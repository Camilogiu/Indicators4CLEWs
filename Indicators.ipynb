{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Indicators4CLEWs**  \n",
    "**Original code:** Camilla Lo Giudice  \n",
    "**Supervision:** Francesco Gardumi and Daniel Adshead  \n",
    "**Funding:** IAM COMPACT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the notebook\n",
    "\n",
    "The Notebook can be divided into six sections:  \n",
    "- 1. Initialization\n",
    "- 2. Creation of the directories\n",
    "- 3. Conversion of model input *Data.txt* files into .csv files using otoole\n",
    "- 4. Conversion of model *results.txt* files into 5 result files:\n",
    "    - converted_data.csv\n",
    "    - converted_data_TS.csv : contains all the results with different timeslices\n",
    "    - converted_data_MoO.csv: contains all the results with different modes of operations\n",
    "    - converted_data_Emissions.csv : contains all the results with emission types\n",
    "    - converted_data_MoO_Emissions.csv : contains all the results with emission types and modes of operation\n",
    "- 5. Indicators\n",
    "- 6. Visualization\n",
    "\n",
    "Each part will be further explained and the user will be guided through each step of the notebook. Users are required to customize the naming convention used in their specific model in the section *Configuration*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration - to be filled by the user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part the user has to select the indicators of interest for the analysis. The input and output data used by the user might affect the outcome. For instance, if a result or imput data is missing it won't be possible to display the indicator. \n",
    "\n",
    "1. **How to select the indicator**  \n",
    "For each indicator type the boolean *True* if the indicator is of interest, *False* otherwise\n",
    "\n",
    "2. **Input the name of the variables**  \n",
    "Each model can have similar but different naming conventions for the same technologies or commodities. Input the specific naming convention used in your model. For example *LNDFOR* if that is the name used for the land covered by forest. This will have to be done in the sub-section *Naming convention*. \n",
    "\n",
    "*Assumptions*\n",
    "\n",
    "1) The workflow will assumes a standard format for the crops naming convention: **LND- Crop type - managment level - Irrigated/rainfed.**  \n",
    "For example, if the model has an irrigated maize crop with a high managment level, the name will be: LND-MAI-H-I --> **LNDMAIHI**  \n",
    "\n",
    "2) The same applies for other land types: all of them start with **LND- type.** For example forest will be LND - FOR --> **LNDFOR**\n",
    "\n",
    "3) If there are crop imports, it is assumed that the naming convention will be **IMP** + the same crop names used for the other technolgies. For example for maize, it will be **IMPMAI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicators\n",
    "\n",
    "Select *True* or *False* for each indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_Cover = True\n",
    "Harvested_Area = True\n",
    "Irrigated_Area = True\n",
    "Yield = True\n",
    "BHI = True                                  #Biodiversity Habitat Index\n",
    "NE = True                                   #Net emissions\n",
    "ws_aa = True                                #Average annual water stress\n",
    "Crop_IDR = True                             #Crop import dependency ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naming convention\n",
    "\n",
    "Modify the following cell with the varibale names used in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest cover indicator\n",
    "\n",
    "Forest_Land = [\"LNDFOR\"]        #Technology for forest cover\n",
    "Total_Land = [\"MINLND\"]         #Technology for the land resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harvested area indicator\n",
    "\"\"\"\n",
    "Create a list of crops consistent with the naming convention used in your model. \n",
    "This will ensure more flexibility to the workflow. \n",
    "The following list provides commonly used crop names in CLEWs models.\n",
    "\n",
    "Maize = [\"MAI\"]\n",
    "Rice = [\"RIC\"] \n",
    "Cereals = [\"CER\"]\n",
    "Coffee = [\"COF\"]\n",
    "Oilseeds = [\"OIL\"]\n",
    "Pulses = [\"PUL\"]\n",
    "Sugarcane = [\"SUGC\"]\n",
    "Sorghum = [\"SOR\"]\n",
    "Wheat = [\"WHEAT\"]\n",
    "Barley = [\"BAR\"]\n",
    "Soybeans = [\"SOY\"]\n",
    "Other_Crops = [\"OTC\"]\"\n",
    "\n",
    "Example with this list: Crops = [\"MAI\", \"RIC\", \"CER\", \"COF\", \"OIL\", \"PUL\", \"SUGC\", \"SOR\", \"WHEAT\", \"BAR\", \"SOY\", \"OTC\"]\n",
    "\"\"\"\n",
    "\n",
    "Crops = [\"CER\", \"WHE\", \"SOR\", \"COF\", \"BRL\", \"MAI\", \"OTC\"]\n",
    "\n",
    "Irrigated = [\"I\"]                   #Convention for irrigated crops rrigated crops\n",
    "Rainfed = [\"R\"]                     #Convention for rainfed crops rrigated crops \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Managment_level = True     # Select True if your model uses management levels and then define your naming convention\n",
    "\n",
    "\"\"\"\n",
    "Create a list of managment levels if Managment_level = True. \n",
    "The following list provides commonly used names in CLEWs models.\n",
    "\n",
    "High_Management = [\"H\"]  \n",
    "Intermediate_Management = [\"I\"]\n",
    "Low_Management = [\"L\"]\n",
    "\n",
    "Example list: Management_Levels = [\"H\", \"I\", \"L\"]\n",
    "\"\"\"\n",
    "Management_Levels = [\"H\", \"L\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yield\n",
    "Yield_Unit = \"Mton/10³km²\"     #This unit refer to the ratio between crop production (e.g ton) over the harvested area (e.g ha). Specify the units used in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biodiversity Habitat Index (BHI)\n",
    "\n",
    "Original_Forest_area = 452         # Input the original forest area of your country. Make sure the unit of the area is consistent with the unit used in your model (e.g. km², ha, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Net emissions (NE) indicator\n",
    "\n",
    "Emission_Type = [\"CO2eq\"]                   # Change according to your model. If your model has only CO2 emissions, use [\"CO2\"]. If it has more emission types then use the CO2 equivalent\n",
    "Mode_of_Operation = [\"1\"]                   #Change only if there is more than 1 mode of operation and the emissions are not associated to the first one\n",
    "Unit_of_measure = \"Mton\"                    # Unit of measure for the emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average annual water stress\n",
    "\n",
    "\"\"\"\n",
    "Input the name of the commodities used for the water supply.\n",
    "This entails water for public use, power sector or irrigation.\n",
    "\"\"\"\n",
    "\n",
    "Initial_water_stress = 0.3  # Add the value of the initial water stress in the modelled country for the reference year.\n",
    "                            # You can refer to the water risk atlas --> Water stress (https://www.wri.org/applications/aqueduct/water-risk-atlas)\n",
    "                             \n",
    "#Input the name of the model commodities  \n",
    "Public_water = [\"PUBWAT\"]                  # Commodity name for public water\n",
    "PWR_water = [\"PWRWAT\"]                     # Commodity name for cooling thermal power plants\n",
    "Irrigation_water = [\"AGRWAT\"]              # Commodity name for irrigation water\n",
    "Surface_water = [\"WTRSUR\"]                 # Commodity name for surface water\n",
    "Ground_water = [\"WTRGWT\"]                  # Commodity name for groundwater\n",
    "Evapotranspiration = [\"WTREVT\"]            # Commodity name for evapotranspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python modules or libraries\n",
    "\n",
    "# Numerical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import errno\n",
    "\n",
    "# System & Other\n",
    "import os\n",
    "import re\n",
    "from otoole import convert\n",
    "import csv\n",
    "\n",
    "#Plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creation of the directories  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input data into csv files\n",
    "ROOT_DIR = os.path.abspath(os.curdir)\n",
    "\n",
    "#data and results input by the user\n",
    "conversion_folder = \"convert_from\"\n",
    "input = os.path.join(ROOT_DIR, conversion_folder + \"\\\\\"+ 'data.txt')\n",
    "output = os.path.join(ROOT_DIR, conversion_folder + \"\\\\\"+ 'results.txt')\n",
    "# Path to the configuration file\n",
    "config_file = os.path.join(ROOT_DIR, \"config_com.yaml\")  # Update this path as needed\n",
    "\n",
    "#folder where to save the converted csv files\n",
    "Final_Data= os.path.join(ROOT_DIR, 'Data')\n",
    "if not os.path.exists(Final_Data):\n",
    "    try:\n",
    "        os.makedirs(Final_Data)\n",
    "    except OSError as exc: \n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "Final_results= os.path.join(ROOT_DIR, 'Results')\n",
    "if not os.path.exists(Final_results):\n",
    "    try:\n",
    "        os.makedirs(Final_results)\n",
    "    except OSError as exc: \n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "converted_input = os.path.join(ROOT_DIR, Final_Data + \"\\\\\"+ 'Model input')\n",
    "if not os.path.exists(converted_input):\n",
    "    try:\n",
    "        os.makedirs(converted_input)\n",
    "    except OSError as exc: \n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "converted_output = os.path.join(ROOT_DIR, Final_Data + \"\\\\\"+ 'Model output')\n",
    "if not os.path.exists(converted_output):\n",
    "    try:\n",
    "        os.makedirs(converted_output)\n",
    "    except OSError as exc: \n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "Plots = os.path.join(ROOT_DIR, 'Plots')\n",
    "if not os.path.exists(Plots):\n",
    "    try:\n",
    "        os.makedirs(Plots)\n",
    "    except OSError as exc: \n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conversion of model input Data.txt files into csv\n",
    "This step uses the otoole environment for converting input data into csv files.Then the following three cells convert the results.txt file into three csv files: one with technologies with modes of operation, one with values per each time slice and one with only annual values (not considering neither modes of operation nor time-slices). The converted outputs will be stored into Data/Model input and in Data/Model output folders. The first one is used for the data converted from the data.txt file, while the second one contains the data converted from the results.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix txt file\n",
    "\n",
    "def fix_txt_file(input):\n",
    "    \"\"\"\n",
    "    Fixes the format of the data.txt file into a new data_fixed.txt. \n",
    "    The fixed parameters are `UDCTag`, `OperationalLifeStorage`, `StorageLevelStart`, and `UDCConstant`.\n",
    "    \n",
    "    \"\"\"\n",
    "    output_file = input.replace('.txt', '_fixed.txt')\n",
    "\n",
    "    params_single_line_fix = [\n",
    "        \"UDCTag\",\n",
    "        \"OperationalLifeStorage\",\n",
    "        \"StorageLevelStart\"\n",
    "    ]\n",
    "\n",
    "    params_udc_constant = [\"UDCConstant\"]\n",
    "\n",
    "    with open(input, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    fixed_lines = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        fixed = False\n",
    "\n",
    "        for param in params_single_line_fix:\n",
    "            if line.startswith(f\"param {param} default\"):\n",
    "                if i + 3 < len(lines):\n",
    "                    line2 = lines[i + 1].strip()\n",
    "                    line4 = lines[i + 3].strip()\n",
    "                    if line2 == \":=\" and line4 == \";\":\n",
    "                        cleaned_line = re.sub(r'\\s*:\\s*$', '', line)\n",
    "                        cleaned_line = re.sub(r'\\s*:=\\s*$', '', cleaned_line)\n",
    "                        fixed_lines.append(f\"{cleaned_line} :=\\n\")\n",
    "                        fixed_lines.append(\";\\n\")\n",
    "                        i += 4\n",
    "                        fixed = True\n",
    "                        break\n",
    "\n",
    "        for param in params_udc_constant:\n",
    "            if line.startswith(f\"param {param} default\"):\n",
    "                if i + 5 < len(lines):\n",
    "                    line5 = lines[i + 5].strip()\n",
    "                    if line5 == \";\":\n",
    "                        cleaned_line = re.sub(r'\\s*:\\s*$', '', line)\n",
    "                        cleaned_line = re.sub(r'\\s*:=\\s*$', '', cleaned_line)\n",
    "                        fixed_lines.append(f\"{cleaned_line} :=\\n\")\n",
    "                        fixed_lines.append(\";\\n\")\n",
    "                        i += 6\n",
    "                        fixed = True\n",
    "                        break\n",
    "\n",
    "        if not fixed:\n",
    "            fixed_lines.append(lines[i])\n",
    "            i += 1\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.writelines(fixed_lines)\n",
    "\n",
    "    print(f\"Fixed input file created: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "fixed_input_file = fix_txt_file(input)\n",
    "input_fixed = os.path.join(ROOT_DIR, conversion_folder + \"\\\\\"+ 'data_fixed.txt')\n",
    "print(f\"Fixed file created at: {fixed_input_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input data to CSV files\n",
    "\n",
    "def convert_input_to_csv(config_path, input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts a data.txt file into CSV files and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    config_path : str\n",
    "        Path to the configuration file.\n",
    "    input_path : str\n",
    "        Path to the input data_fixed.txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        try:\n",
    "            os.makedirs(output_folder)\n",
    "        except OSError as exc:\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "    # Perform the conversion\n",
    "    try:\n",
    "        success = convert(\n",
    "            config=config_path,\n",
    "            from_format=\"datafile\",\n",
    "            to_format=\"csv\",\n",
    "            from_path=input_path,\n",
    "            to_path=output_folder,\n",
    "            write_defaults=False,\n",
    "            keep_whitespace=False,\n",
    "        )\n",
    "        return success\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "    \n",
    "# Convert the input data to CSV files\n",
    "conversion_success = convert_input_to_csv(config_file, input_fixed, converted_input)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_input}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conversion of model results.txt file into csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the results to CSV files\n",
    "\n",
    "def convert_results_to_csv(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts the MUIO results.txt file into CSV files and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_path : str\n",
    "        Path to the input txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "  \n",
    "    try:\n",
    "        # Open the input txt file\n",
    "        with open(input_path, 'r') as txt_file:\n",
    "            lines = txt_file.readlines()\n",
    "\n",
    "        # Prepare the output CSV file\n",
    "        output_csv_path = os.path.join(output_folder, \"converted_data.csv\")\n",
    "        with open(output_csv_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the header row\n",
    "            csv_writer.writerow([\"PARAMETER\", \"REGION\", \"TECHNOLOGY\", \"YEAR\", \"VALUE\",])\n",
    "\n",
    "            # Parse each line in the txt file\n",
    "            for line in lines:\n",
    "                # Split the line into columns based on fixed-width formatting\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 3:\n",
    "                    continue  # Skip invalid lines\n",
    "\n",
    "                # Extract the parameter, and values\n",
    "                parameter_info = parts[1]\n",
    "                value = parts[2]\n",
    "\n",
    "                # Parse the parameter info (e.g., NewCapacity(RE1,PWRHYDLRG,2020))\n",
    "                if \"(\" in parameter_info and \")\" in parameter_info:\n",
    "                    parameter, details = parameter_info.split(\"(\")\n",
    "                    details = details.strip(\")\").split(\",\")\n",
    "                    if len(details) == 3:\n",
    "                        region, technology, year = details\n",
    "                        # Write the parsed data to the CSV file\n",
    "                        csv_writer.writerow([parameter, region, technology, year, value,])\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function to convert the custom txt file to CSV\n",
    "conversion_success = convert_results_to_csv(output, converted_output)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_output}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the results to CSV files with TimeSlices\n",
    "\n",
    "def convert_resultsTS_to_csv(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts the MUIO results.txt file into CSV files with time-slices and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_path : str\n",
    "        Path to the input txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "  \n",
    "    try:\n",
    "        # Open the input txt file\n",
    "        with open(input_path, 'r') as txt_file:\n",
    "            lines = txt_file.readlines()\n",
    "\n",
    "        # Prepare the output CSV file\n",
    "        output_csv_TS_path = os.path.join(output_folder, \"converted_data_TS.csv\")\n",
    "        with open(output_csv_TS_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the header row\n",
    "            csv_writer.writerow([\"PARAMETER\", \"REGION\", \"TECHNOLOGY\",\"TIMESLICE\",\"YEAR\", \"VALUE\",])\n",
    "\n",
    "            # Parse each line in the txt file\n",
    "            for line in lines:\n",
    "                # Split the line into columns based on fixed-width formatting\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 4:\n",
    "                    continue  # Skip invalid lines\n",
    "\n",
    "                # Extract the parameter, and values\n",
    "                parameter_info = parts[1]\n",
    "                value = parts[2]\n",
    "\n",
    "                # Parse the parameter info \n",
    "                if \"(\" in parameter_info and \")\" in parameter_info:\n",
    "                    parameter, details = parameter_info.split(\"(\")\n",
    "                    details = details.strip(\")\").split(\",\")\n",
    "                    if len(details) == 4:\n",
    "                        region, technology, time_slice, year = details\n",
    "                        \n",
    "                        # Skip if the time-slice is a number\n",
    "                        if time_slice.isdigit():\n",
    "                            continue\n",
    "\n",
    "                        # Skip if the parameter is \"AnnualTechnologyEmission\" or \"InputToTotalCapacity\"\n",
    "                        if parameter in [\"AnnualTechnologyEmission\", \"InputToTotalCapacity\", \"Demand\"]:\n",
    "                            continue\n",
    "\n",
    "                        # Write the parsed data to the CSV file\n",
    "                        csv_writer.writerow([parameter, region, technology, time_slice, year, value,])\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function to convert the custom txt file to CSV\n",
    "conversion_success = convert_resultsTS_to_csv(output, converted_output)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_output}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the results to CSV files with Modes of operation\n",
    "\n",
    "def convert_resultsMoO_to_csv(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts the MUIO results.txt with modes of operation (MoO) into CSV files with time-slices and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_path : str\n",
    "        Path to the input txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "  \n",
    "    try:\n",
    "        # Open the input txt file\n",
    "        with open(input_path, 'r') as txt_file:\n",
    "            lines = txt_file.readlines()\n",
    "\n",
    "        # Prepare the output CSV file\n",
    "        output_csv_MoO_path = os.path.join(output_folder, \"converted_data_MoO.csv\")\n",
    "        with open(output_csv_MoO_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the header row\n",
    "            csv_writer.writerow([\"PARAMETER\", \"REGION\", \"TECHNOLOGY\",\"MODE_OF_OPERATION\",\"YEAR\", \"VALUE\",])\n",
    "\n",
    "            # Parse each line in the txt file\n",
    "            for line in lines:\n",
    "                # Split the line into columns based on fixed-width formatting\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 4:\n",
    "                    continue  # Skip invalid lines\n",
    "\n",
    "                # Extract the parameter, and values\n",
    "                parameter_info = parts[1]\n",
    "                value = parts[2]\n",
    "\n",
    "                # Parse the parameter info \n",
    "                if \"(\" in parameter_info and \")\" in parameter_info:\n",
    "                    parameter, details = parameter_info.split(\"(\")\n",
    "                    details = details.strip(\")\").split(\",\")\n",
    "                    if len(details) == 4:\n",
    "                        region, technology, mode_of_operation, year = details\n",
    "                        if mode_of_operation.isdigit(): # Modes of operaion can be only > 1\n",
    "                            # Write the parsed data to the CSV file\n",
    "                            csv_writer.writerow([parameter, region, technology, mode_of_operation, year, value,])\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function to convert the custom txt file to CSV\n",
    "conversion_success = convert_resultsMoO_to_csv(output, converted_output)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_output}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the emission results to CSV files \n",
    "\n",
    "def convert_resultsEMI_to_csv(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts the MUIO results.txt file into CSV files with emissions and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_path : str\n",
    "        Path to the input txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "  \n",
    "    try:\n",
    "        # Open the input txt file\n",
    "        with open(input_path, 'r') as txt_file:\n",
    "            lines = txt_file.readlines()\n",
    "\n",
    "        # Prepare the output CSV file\n",
    "        output_csv_EMI_path = os.path.join(output_folder, \"converted_data_Emissions.csv\")\n",
    "        with open(output_csv_EMI_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the header row\n",
    "            csv_writer.writerow([\"PARAMETER\", \"REGION\", \"TECHNOLOGY\",\"EMISSION\",\"YEAR\", \"VALUE\",])\n",
    "\n",
    "            # Parse each line in the txt file\n",
    "            for line in lines:\n",
    "                # Split the line into columns based on fixed-width formatting\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 4:\n",
    "                    continue  # Skip invalid lines\n",
    "\n",
    "                # Extract the parameter, and values\n",
    "                parameter_info = parts[1]\n",
    "                value = parts[2]\n",
    "\n",
    "                # Parse the parameter info \n",
    "                if \"(\" in parameter_info and \")\" in parameter_info:\n",
    "                    parameter, details = parameter_info.split(\"(\")\n",
    "                    details = details.strip(\")\").split(\",\")\n",
    "                    if len(details) == 4:\n",
    "                        region, technology, emission, year = details\n",
    "                        \n",
    "                        # Skip if the time-slice is a number\n",
    "                        if emission.isdigit():\n",
    "                            continue\n",
    "\n",
    "                        # Skip if the parameter is \"AnnualTechnologyEmission\" or \"InputToTotalCapacity\"\n",
    "                        if parameter in [ \"RateOfTotalActivity\",\"InputToTotalCapacity\", \"Demand\"]:\n",
    "                            continue\n",
    "\n",
    "                        # Write the parsed data to the CSV file\n",
    "                        csv_writer.writerow([parameter, region, technology, emission, year, value,])\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function to convert the custom txt file to CSV\n",
    "conversion_success = convert_resultsEMI_to_csv(output, converted_output)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_output}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the emission results to CSV files with Modes of Operation (MoO)\n",
    "\n",
    "def convert_resultsEMIMoO_to_csv(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts the MUIO results.txt file into CSV files with emissions with MoO and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_path : str\n",
    "        Path to the input txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the input txt file\n",
    "        with open(input_path, 'r') as txt_file:\n",
    "            lines = txt_file.readlines()\n",
    "\n",
    "        # Prepare the output CSV file\n",
    "        output_csv_EMIMoO_path = os.path.join(output_folder, \"converted_data_MoO_Emissions.csv\")\n",
    "        with open(output_csv_EMIMoO_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the header row\n",
    "            csv_writer.writerow([\"PARAMETER\", \"REGION\", \"TECHNOLOGY\", \"EMISSION\", \"MODE_OF_OPERATION\", \"YEAR\", \"VALUE\"])\n",
    "\n",
    "            # Parse each line in the txt file\n",
    "            for line in lines:\n",
    "                # Split the line into columns based on fixed-width formatting\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 3:  # Ensure the line has enough parts\n",
    "                    #print(f\"Skipping line (not enough parts): {line.strip()}\")\n",
    "                    continue\n",
    "\n",
    "                # Extract the parameter and value\n",
    "                parameter_info = parts[1]\n",
    "                value = parts[2]\n",
    "\n",
    "                # Parse the parameter info\n",
    "                if \"(\" in parameter_info and \")\" in parameter_info:\n",
    "                    parameter, details = parameter_info.split(\"(\")\n",
    "                    details = details.strip(\")\").split(\",\")\n",
    "                    if len(details) == 5:  # Ensure the details have the expected structure\n",
    "                        region, technology, emission, mode, year = details\n",
    "\n",
    "                        if \"Emission\" not in parameter:\n",
    "                            continue\n",
    "\n",
    "                        if not mode.strip().isdigit():\n",
    "                            continue\n",
    "\n",
    "                        if parameter in [ \"RateOfActivity\"]:\n",
    "                            continue\n",
    "\n",
    "                        # Write the parsed data to the CSV file\n",
    "                        csv_writer.writerow([parameter, region, technology, emission, mode, year, value])\n",
    "                    \n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function to convert the custom txt file to CSV\n",
    "conversion_success = convert_resultsEMIMoO_to_csv(output, converted_output)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_output}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Indicators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Forest cover  \n",
    "The forest cover shows the share of land covered by forest mesured in %. <br><br>\n",
    "$$Forest\\_Cover = \\frac{Total\\_land\\_covered\\_by\\_forest}{Total\\_land}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the cell for the Forest Cover indicator\n",
    "if Forest_Cover == False:\n",
    "    exit()\n",
    "\n",
    "input_csv = os.path.join(converted_output, 'converted_data.csv')\n",
    "output_csv = os.path.join(Final_results, 'Forest_cover.csv')\n",
    "\n",
    "# Read the input CSV file\n",
    "try:\n",
    "    data = pd.read_csv(input_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_csv} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Filter the data \n",
    "filtered_data = data[data[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {\"INDICATOR\": [], \"VALUE\": [], \"UNIT\": [], \"YEAR\": []}\n",
    "           \n",
    "\n",
    "# Loop through each year and calculate the ratio\n",
    "for year in filtered_data[\"YEAR\"].unique():\n",
    "    # Filter data for the current year\n",
    "    year_data = filtered_data[filtered_data[\"YEAR\"] == year]\n",
    "    \n",
    "    # Get the value for forest land\n",
    "    lndfor_value = year_data[year_data[\"TECHNOLOGY\"].isin(Forest_Land)][\"VALUE\"].sum()\n",
    "    \n",
    "    # Get the value for total land\n",
    "    rsclnd_value = year_data[year_data[\"TECHNOLOGY\"].isin(Total_Land)][\"VALUE\"].sum()\n",
    "    \n",
    "    # Calculate the ratio if RSCLND value is not zero\n",
    "    if rsclnd_value != 0:\n",
    "        ratio = round((lndfor_value / rsclnd_value) * 100, 3)\n",
    "        results[\"INDICATOR\"].append(\"ForestCover\")\n",
    "        results[\"VALUE\"].append(ratio)\n",
    "        results[\"UNIT\"].append(\"%\")\n",
    "        results[\"YEAR\"].append(year)\n",
    "        \n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Forest cover indicators have been successfully saved to {output_csv}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Harvested area  \n",
    "This indicator shows the share of total harvested land (both rainfed or irrigated), calculated as <br><br>\n",
    "$$Harvested\\_Area = \\frac{Total\\_land\\_harvested}{Total\\_land}$$  \n",
    "Note that the type of crops might vary greatly depending on the case study country. If a specific crop is missing from the ones proposed, add it in the configuration cell. Additionally, models can vary in complexity. A part from distinguishing between rainfed and irrigated, it is possible to model also three generic input/management levels defined in the GAEZ v4.0 model documentation:  \n",
    "- *Low level input:*  \n",
    "   Traditional managment assumption  \n",
    "- *Intermediate level inputs:*  \n",
    "   Improved managment assumption\n",
    "- *High level input:*  \n",
    "   Advanced managment assumption\n",
    "\n",
    "For this indicator the configuration cell will be split in three main cells: managment level, crop types and irrigated/rainfed. This is due to the high flexiility that each user has in shaping the land use. The workflow will assume the standard format used for naming crops: **LND- Crop type - managment level - Irrigated/rainfed.**  \n",
    "\n",
    "For example, if the model has an irrigated maize crop with a high managment level, the name will be: LND-MAI-H-I --> **LNDMAIHI**  \n",
    "\n",
    "\n",
    "For the GAEZ v4 model documentation refer to https://openknowledge.fao.org/server/api/core/bitstreams/6b7b9b4a-dbac-4af4-a2cb-26aff33a30e5/content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Harvested area indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell for the harvested Area indicator\n",
    "if Harvested_Area == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "input_csv = os.path.join(converted_output, 'converted_data.csv')\n",
    "output_csv = os.path.join(Final_results, 'Harvested_area.csv')\n",
    "\n",
    "# Read the input CSV file\n",
    "try:\n",
    "    data = pd.read_csv(input_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_csv} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Filter the data for the parameter \"TotalTechnologyAnnualActivity\"\n",
    "filtered_data = data[data[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {\"INDICATOR\": [], \"VALUE\": [], \"UNIT\": [], \"YEAR\": []}\n",
    "\n",
    "# Build the regular expression for filtering technologies\n",
    "crop_regex = \"|\".join(Crops)  \n",
    "irrigation_regex = \"|\".join(Irrigated + Rainfed)  \n",
    "\n",
    "# Check if management levels are used\n",
    "if Managment_level:\n",
    "    management_regex = \"|\".join(Management_Levels)  \n",
    "    technology_regex = f\"LND({crop_regex})({management_regex})({irrigation_regex})\"\n",
    "else:\n",
    "    technology_regex = f\"LND({crop_regex})({irrigation_regex})\"\n",
    "\n",
    "# calculate the ratio\n",
    "for year in filtered_data[\"YEAR\"].unique():\n",
    "    # Filter data for the current year\n",
    "    year_data = filtered_data[filtered_data[\"YEAR\"] == year]\n",
    "\n",
    "    # Filter technologies that match the naming convention\n",
    "    harvested_area_data = year_data[year_data[\"TECHNOLOGY\"].str.contains(technology_regex, flags=re.IGNORECASE, na=False)]\n",
    "\n",
    "    # Calculate the sum of harvested area\n",
    "    harvested_area_sum = harvested_area_data[\"VALUE\"].sum()\n",
    "\n",
    "    # Get the total land value for the year\n",
    "    total_land_data = year_data[year_data[\"TECHNOLOGY\"].isin(Total_Land)]\n",
    "    total_land_value = total_land_data[\"VALUE\"].sum()\n",
    "\n",
    "    # Calculate the ratio if total land value is not zero\n",
    "    if total_land_value != 0:\n",
    "        ratio = round((harvested_area_sum / total_land_value) * 100, 3)  \n",
    "        results[\"INDICATOR\"].append(\"HarvestedArea\")\n",
    "        results[\"VALUE\"].append(ratio)\n",
    "        results[\"UNIT\"].append(\"%\")\n",
    "        results[\"YEAR\"].append(year)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "print(f\"Harvested area indicators have been successfully saved to {output_csv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Area under irrigation  \n",
    "This indicator shows the share of total irrigated land, calculated as: <br><br>\n",
    "$$Irrigated\\_Area = \\frac{Total\\_land\\_Irrigated}{Total\\_land\\_harvested}$$  \n",
    "\n",
    "Note that the configuration cells are the same as for the indicator above. Make sure to run that ones before running the indicator code cell. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Irrigated area indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell for the Irrigated Area indicator\n",
    "if Irrigated_Area == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "input_csv = os.path.join(converted_output, 'converted_data.csv')\n",
    "output_csv = os.path.join(Final_results, 'Irrigated_area.csv')\n",
    "\n",
    "# Read the input CSV file\n",
    "try:\n",
    "    data = pd.read_csv(input_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_csv} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Filter the data for the parameter \"TotalTechnologyAnnualActivity\"\n",
    "filtered_data = data[data[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "\n",
    "results = {\"INDICATOR\": [], \"VALUE\": [], \"UNIT\": [], \"YEAR\": []}\n",
    "\n",
    "crop_regex = \"|\".join(Crops)  \n",
    "irrigation_regex = \"|\".join(Irrigated)  \n",
    "rainfed_regex = \"|\".join(Rainfed) \n",
    "\n",
    "# Check if management levels are used\n",
    "if Managment_level:\n",
    "    management_regex = \"|\".join(Management_Levels)  # Combine management levels dynamically\n",
    "    irrigated_technology_regex = f\"LND({crop_regex})({management_regex})({irrigation_regex})\"\n",
    "    total_harvested_technology_regex = f\"LND({crop_regex})({management_regex})({irrigation_regex}|{rainfed_regex})\"\n",
    "else:\n",
    "    irrigated_technology_regex = f\"LND({crop_regex})({irrigation_regex})\"\n",
    "    total_harvested_technology_regex = f\"LND({crop_regex})({irrigation_regex}|{rainfed_regex})\"\n",
    "\n",
    "# Loop through each year and calculate the ratio\n",
    "for year in filtered_data[\"YEAR\"].unique():\n",
    "    # Filter data for the current year\n",
    "    year_data = filtered_data[filtered_data[\"YEAR\"] == year]\n",
    "\n",
    "    # Filter technologies for irrigated area (numerator)\n",
    "    irrigated_area_data = year_data[year_data[\"TECHNOLOGY\"].str.contains(irrigated_technology_regex, flags=re.IGNORECASE, na=False)]\n",
    "    irrigated_area_sum = irrigated_area_data[\"VALUE\"].sum()\n",
    "\n",
    "    # Filter technologies for total harvested area (denominator)\n",
    "    total_harvested_area_data = year_data[year_data[\"TECHNOLOGY\"].str.contains(total_harvested_technology_regex, flags=re.IGNORECASE, na=False)]\n",
    "    total_harvested_area_sum = total_harvested_area_data[\"VALUE\"].sum()\n",
    "\n",
    "    # Calculate the ratio if total harvested area is not zero\n",
    "    if total_harvested_area_sum != 0:\n",
    "        ratio = round((irrigated_area_sum / total_harvested_area_sum) * 100, 3)  \n",
    "        results[\"INDICATOR\"].append(\"Irrigated Area\")\n",
    "        results[\"VALUE\"].append(ratio)\n",
    "        results[\"UNIT\"].append(\"%\")\n",
    "        results[\"YEAR\"].append(year)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Irrigated area indicators have been successfully saved to {output_csv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Crop yield\n",
    "\n",
    "This indicator represents the overall yield of a given crop. Note that this yield is different from the  one the user has to input into the model. The output activity ratio is indeed crop specific and varies according to the type of farming considered (e.g rainfed/irrigated or high/low mechanization). This indicator estimates the overall yield, defined as the ratio between the total crop production over the total harvested land for that crop:  <br><br><br>\n",
    "\n",
    "\n",
    " $$Crop\\_yield = \\frac{Total\\_Production}{Total\\_harvested\\_Area} $$  \n",
    "\n",
    " Make sure to run the configuration cells in 5.2 for defining the crops. This indicator assumes also that the name of the crop commodity is the same as one used in the technologies (e.g if for Maize was \"MAI\", then the same will be for the commodity). The *format* of the commodity name is consistent to the one adopted in most of CLEWs models: CRP + name --> e.g CRP-MAI --> **CRPMAI**  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Yield indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell for the Crop yield indicator\n",
    "if Yield == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "output_activity_ratio_csv = os.path.join(converted_input, 'OutputActivityRatio.csv')\n",
    "total_technology_activity_csv = os.path.join(converted_output, 'converted_data.csv')\n",
    "output_csv = os.path.join(Final_results, 'Crop_Yield.csv')\n",
    "\n",
    "try:\n",
    "    output_activity_ratio_data = pd.read_csv(output_activity_ratio_csv)\n",
    "    total_technology_activity_data = pd.read_csv(total_technology_activity_csv)\n",
    "\n",
    "    # Filter for the correct parameter\n",
    "    total_technology_activity_data = total_technology_activity_data[\n",
    "        total_technology_activity_data[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"\n",
    "    ]\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    # raise or return instead of exit() in notebooks\n",
    "    raise\n",
    "\n",
    "results = {\"CROP\": [], \"VALUE\": [], \"UNIT\": [], \"YEAR\": []}\n",
    "\n",
    "# filter technologies\n",
    "crop_regex = \"|\".join(Crops)  \n",
    "irrigation_regex = \"|\".join(Irrigated + Rainfed)  \n",
    "\n",
    "# Include management levels in the regex if enable\n",
    "if Managment_level:                           \n",
    "    management_regex = \"|\".join(Management_Levels)\n",
    "    technology_regex = f\"LND({crop_regex})({management_regex})({irrigation_regex})\"\n",
    "else:\n",
    "    technology_regex = f\"LND({crop_regex})({irrigation_regex})\"                      \n",
    "\n",
    "\n",
    "for crop in Crops:\n",
    "    crop_technology_regex = f\"LND{crop}\"  # Matches technologies like LNDMAI, LNDRIC\n",
    "    commodity_name = f\"CRP{crop}\"  # Matches commodities like CRPMAI, CRPRIC\n",
    "\n",
    "    # Filter OutputActivityRatio data for the current crop\n",
    "    crop_output_data = output_activity_ratio_data[\n",
    "        (output_activity_ratio_data[\"TECHNOLOGY\"].str.contains(technology_regex, na=False)) &\n",
    "        (output_activity_ratio_data[\"COMMODITY\"] == commodity_name)\n",
    "    ]\n",
    "\n",
    "    # Filter TotalTechnologyAnnualActivity data for the current crop\n",
    "    crop_activity_data = total_technology_activity_data[\n",
    "        total_technology_activity_data[\"TECHNOLOGY\"].str.contains(technology_regex, na=False)\n",
    "    ]\n",
    "\n",
    "    # Loop through each year to calculate the yield\n",
    "    for year in crop_activity_data[\"YEAR\"].unique():\n",
    "        # Filter data for the current year\n",
    "        year_output_data = crop_output_data[crop_output_data[\"YEAR\"] == year]\n",
    "        year_activity_data = crop_activity_data[crop_activity_data[\"YEAR\"] == year]\n",
    "\n",
    "        # Calculate the numerator: sum(OutputActivityRatio * TotalTechnologyAnnualActivity)\n",
    "        numerator = 0\n",
    "        for _, row in year_output_data.iterrows():\n",
    "            technology = row[\"TECHNOLOGY\"]\n",
    "            output_ratio = row[\"VALUE\"]\n",
    "            # Find the corresponding activity value for the same technology\n",
    "            activity_value = year_activity_data[year_activity_data[\"TECHNOLOGY\"] == technology][\"VALUE\"].sum()\n",
    "            numerator += output_ratio * activity_value\n",
    "\n",
    "        # Calculate the denominator: sum(TotalTechnologyAnnualActivity)\n",
    "        denominator = year_activity_data[\"VALUE\"].sum()\n",
    "\n",
    "        # Calculate the yield \n",
    "        if denominator != 0:\n",
    "            yield_value = round(numerator / denominator, 3) \n",
    "            results[\"CROP\"].append(crop)\n",
    "            results[\"VALUE\"].append(yield_value)\n",
    "            results[\"UNIT\"].append(Yield_Unit) \n",
    "            results[\"YEAR\"].append(year)\n",
    "                    \n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Yield indicators have been successfully saved to {output_csv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Biodiversity\n",
    "\n",
    "The Biodiversity Habitat Index (BHI) assesses the effects of habitat loss, degradation, and fragmentation on the retention of terrestrial biodiversity in a region. The indicator exploits the species-area relationship: <br><br><br>\n",
    "\n",
    "\n",
    " $$BHI = \\frac{Forest\\_Area\\_Retained}{Original\\_Forest\\_Area}^{0.25} $$\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " In this analysis, 0.25 represents the exponent *z* of the species–area relationship, a widely accepted value for this type of assessment.\n",
    " The results show the % increase (or decrease) in biodiversity.\n",
    " Being CLEWs models not spatially explicit, we refered to the simplified relationship presented by Simon Ferrier et al. (2004). For more information refer to: BioScience, Volume 54, Issue 12, December 2004, Pages 1101–1109, https://doi.org/10.1641/0006-3568(2004)054[1101:MMOTBF]2.0.CO;2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BHI indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if BHI == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "input_csv = os.path.join(converted_output, 'converted_data.csv')\n",
    "BHI_output_csv = os.path.join(Final_results, 'BHI.csv')\n",
    "\n",
    "# Read the input CSV file\n",
    "try:\n",
    "    data = pd.read_csv(input_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_csv} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Filter the data for the parameter \"TotalTechnologyAnnualActivity\"\n",
    "filtered_data = data[data[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {\"INDICATOR\": [], \"VALUE\": [], \"UNIT\": [], \"YEAR\": []}\n",
    "\n",
    "# Loop through each year and calculate the BHI\n",
    "for year in filtered_data[\"YEAR\"].unique():\n",
    "    # Filter data for the current year\n",
    "    year_data = filtered_data[filtered_data[\"YEAR\"] == year]\n",
    "    \n",
    "    # Get the value for forest land\n",
    "    lndfor_value = year_data[year_data[\"TECHNOLOGY\"].isin(Forest_Land)][\"VALUE\"].sum()\n",
    "    \n",
    "    # Calculate the BHI\n",
    "    if Original_Forest_area != 0: \n",
    "        ratio = round(((lndfor_value / Original_Forest_area) ** 0.25)*100, 3)\n",
    "        results[\"INDICATOR\"].append(\"BHI\")\n",
    "        results[\"VALUE\"].append(round(ratio, 3))\n",
    "        results[\"UNIT\"].append(\"%\")\n",
    "        results[\"YEAR\"].append(year)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(BHI_output_csv, index=False)\n",
    "\n",
    "print(f\"BHI indicator has been successfully saved to {BHI_output_csv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Net Emissions\n",
    "\n",
    "The Net Emissions (NE) indicator is a quantitative estimation of the net CO2 equivalent produced. It considers direct emissions and land use change emissions which are both output of the CLEWs model. Note that in most CLEWs application the emission activity ratio for forest is negative, taking into account that it works as a carbon sink. The estimation is therefore an algebraic sum of all the technologies with an emission factor associated. The output is already a net balance for each year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if NE == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "input_csv_emissions = os.path.join(converted_output, 'converted_data_Emissions.csv')\n",
    "input_csv_LUC = os.path.join(converted_output, 'converted_data_MoO_Emissions.csv')\n",
    "NE_output_csv = os.path.join(Final_results, 'Net_emissions.csv')\n",
    "\n",
    "# Read emissions file\n",
    "try:\n",
    "    data_emissions = pd.read_csv(input_csv_emissions)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_csv_emissions} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Read LUC file\n",
    "try:\n",
    "    data_LUC = pd.read_csv(input_csv_LUC)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_csv_LUC} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "if data_emissions.empty and data_LUC.empty:\n",
    "    print(\"Both input CSV files are empty.\")\n",
    "    exit()\n",
    "\n",
    "# Filter direct emissions\n",
    "filtered_direct = data_emissions[\n",
    "    (data_emissions[\"PARAMETER\"] == \"AnnualTechnologyEmission\") &\n",
    "    (data_emissions[\"EMISSION\"].isin(Emission_Type))\n",
    "]\n",
    "\n",
    "direct_emissions = filtered_direct.groupby(\"YEAR\")[\"VALUE\"].sum().reset_index()\n",
    "direct_emissions.rename(columns={\"VALUE\": \"DIRECT_EMISSIONS\"}, inplace=True)\n",
    "\n",
    "# Filter LUC emissions\n",
    "filtered_LUC = data_LUC[\n",
    "    (data_LUC[\"PARAMETER\"] == \"EmissionByActivityChange\") &\n",
    "    (data_LUC[\"EMISSION\"].isin(Emission_Type)) &\n",
    "    (data_LUC[\"MODE_OF_OPERATION\"].isin(Mode_of_Operation))\n",
    "]\n",
    "\n",
    "LUC_emissions = filtered_LUC.groupby(\"YEAR\")[\"VALUE\"].sum().reset_index()\n",
    "LUC_emissions.rename(columns={\"VALUE\": \"LUC_EMISSIONS\"}, inplace=True)\n",
    "\n",
    "# Merge and sum\n",
    "merged = pd.merge(direct_emissions, LUC_emissions, on=\"YEAR\", how=\"outer\").fillna(0)\n",
    "merged[\"VALUE\"] = merged[\"DIRECT_EMISSIONS\"] + merged[\"LUC_EMISSIONS\"]\n",
    "merged[\"VALUE\"] = merged[\"VALUE\"].round(3)\n",
    "merged[\"INDICATOR\"] = \"NetEmissions\"\n",
    "merged[\"UNIT\"] = Unit_of_measure\n",
    "\n",
    "results = merged[[\"INDICATOR\", \"VALUE\", \"UNIT\", \"YEAR\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv(NE_output_csv, index=False)\n",
    "\n",
    "print(f\"Net emission indicator has been successfully saved to {NE_output_csv}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Average annual water stress and relative water demand\n",
    "\n",
    "The water stress can be calculated as the ratio of the total water demand over the total available renewable surface and groundwater supplies (also known as relative water demand). It is suitable for models with low temporal resolution. The steps for calculating the indicator are the following: <br><br>\n",
    "*Step 1: calculate the relative water demand* <br><br><br>\n",
    "\n",
    "$$ r = \\frac{Total\\_Annual\\_Gross\\_Demand}{Total\\_Annual\\_Available\\_Water}$$  \n",
    "\n",
    "The annual demand includes public and industrial uses and the demand associated to the power and agricultural sectors.\n",
    "\n",
    "*Step 2: calculate the water average annual stress*<br><br><br>\n",
    "\n",
    "$$ws_{aa} = \\min(1, \\max(0, r))$$  \n",
    "\n",
    "\n",
    "*Step 3: conversion to risk categories*<br><br><br>\n",
    "\n",
    "$$Average\\_Annual\\_score = \\max\\left(0, \\min\\left(5, \\frac{ln(ws_{aa})-ln(0.1)}{ln(2)} +1\\right)\\right)$$  \n",
    "\n",
    "The risk cathegory follows the same values and methodlogy used by WRI and then adapted to a CLEWs model. The code returns two csv files: one for the relative water demand and one with the average water stress per each modelled year.\n",
    "\n",
    "\n",
    "For more information about the methodology adopted by WRI refer to https://files.wri.org/d8/s3fs-public/2023-08/aqueduct-40-technical-note.pdf?VersionId=G_TxTR2LAnlgXGzy7xtdUP_5lmkXJY7d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "IAR_csv = os.path.join(converted_input, \"InputActivityRatio.csv\")\n",
    "OAR_csv = os.path.join(converted_input, \"OutputActivityRatio.csv\")\n",
    "Water_annual_demand_sp_csv = os.path.join(converted_input, \"SpecifiedAnnualDemand.csv\")\n",
    "Water_annual_demand_annual_csv = os.path.join(converted_input, \"AccumulatedAnnualDemand.csv\")\n",
    "output_Activity_csv = os.path.join(converted_output, \"converted_data.csv\")\n",
    "r_csv = os.path.join(Final_results, \"Relative_annual_water_demand.csv\")\n",
    "Annual_average_ws_score = os.path.join(Final_results, \"Annual_average_ws_score.csv\")\n",
    "\n",
    "# Read the input CSV files\n",
    "try:\n",
    "    data_IAR = pd.read_csv(IAR_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {IAR_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_IAR.empty:\n",
    "    print(\"The {IAR_csv} file is empty.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    data_OAR = pd.read_csv(OAR_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {OAR_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_OAR.empty:\n",
    "    print(\"The {OAR_csv} file is empty.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    data_Water_demand_sp = pd.read_csv(Water_annual_demand_sp_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {Water_annual_demand_sp_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_Water_demand_sp[ data_Water_demand_sp[\"COMMODITY\"].isin(Public_water) ].empty:\n",
    "    print(f\"The commodity {Public_water} is not present in {Water_annual_demand_sp_csv}.\")\n",
    "\n",
    "try:\n",
    "    data_Water_demand_annual = pd.read_csv(Water_annual_demand_annual_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {Water_annual_demand_annual_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_Water_demand_annual.empty:\n",
    "    print(\"The {Water_annual_demand_annual_csv} file is empty.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    data_activity = pd.read_csv(output_Activity_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {output_Activity_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_activity.empty:\n",
    "    print(\"The {output_Activity_csv} file is empty.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Water demand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Water demand for cooling thermal power plants\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "    \n",
    "# Filter data_IAR for the commodity PWRWAT\n",
    "filtered_IAR = data_IAR[data_IAR[\"COMMODITY\"].isin(PWR_water)]\n",
    "\n",
    "# Filter data_Rate_activity for the parameter RateOfTotalActivity\n",
    "filtered_activity = data_activity[data_activity[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Merge the two datasets on REGION, TECHNOLOGY, and YEAR\n",
    "merged_data = pd.merge(\n",
    "    filtered_activity,\n",
    "    filtered_IAR,\n",
    "    on=[\"REGION\", \"TECHNOLOGY\", \"YEAR\"],\n",
    "    suffixes=(\"_activity\", \"_iar\")\n",
    ")\n",
    "\n",
    "# Calculate the VALUE for each year, technology, and timeslice\n",
    "merged_data[\"VALUE\"] = merged_data[\"VALUE_activity\"] * merged_data[\"VALUE_iar\"]\n",
    "\n",
    "\n",
    "result = merged_data[[\"TECHNOLOGY\", \"VALUE\", \"YEAR\"]]\n",
    "\n",
    "# Total demand for cooling thermal power plants\n",
    "Df_PWRWAT_demand = result.groupby([\"YEAR\"], as_index=False)[\"VALUE\"].sum()\n",
    "\n",
    "#display(Df_PWRWAT_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Water demand for irrigation\n",
    "\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "    \n",
    "# Filter data_IAR for the commodity PWRWAT\n",
    "filtered_IAR = data_IAR[data_IAR[\"COMMODITY\"].isin(Irrigation_water)]\n",
    "\n",
    "# Filter data_Rate_activity for the parameter RateOfTotalActivity\n",
    "filtered_activity = data_activity[data_activity[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Merge the two datasets on REGION, TECHNOLOGY, and YEAR\n",
    "merged_data = pd.merge(\n",
    "    filtered_activity,\n",
    "    filtered_IAR,\n",
    "    on=[\"REGION\", \"TECHNOLOGY\", \"YEAR\"],\n",
    "    suffixes=(\"_activity\", \"_iar\")\n",
    ")\n",
    "\n",
    "# Calculate the VALUE for each year, technology, and timeslice\n",
    "merged_data[\"VALUE\"] = merged_data[\"VALUE_activity\"] * merged_data[\"VALUE_iar\"]\n",
    "result = merged_data[[\"TECHNOLOGY\", \"VALUE\", \"YEAR\"]]\n",
    "\n",
    "# Total demand for irrigation\n",
    "Df_Irrigation_demand = result.groupby([\"YEAR\"], as_index=False)[\"VALUE\"].sum()\n",
    "\n",
    "#display(Df_Irrigation_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Consumptive use of water\n",
    "\n",
    "\"\"\"\n",
    "consumptive use is the portion of withdrawn \n",
    "water that is no longer available for downstream use. \n",
    "In this case we consider evpotranspiration.\n",
    "\n",
    "\"\"\"\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "    \n",
    "# Filter data_OAR for the commodity PWRWAT\n",
    "filtered_OAR = data_OAR[data_OAR[\"COMMODITY\"].isin(Evapotranspiration)]\n",
    "\n",
    "# Filter data_Rate_activity for the parameter RateOfTotalActivity\n",
    "filtered_activity = data_activity[data_activity[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Merge the two datasets on REGION, TECHNOLOGY, and YEAR\n",
    "merged_data = pd.merge(\n",
    "    filtered_activity,\n",
    "    filtered_OAR,\n",
    "    on=[\"REGION\", \"TECHNOLOGY\", \"YEAR\"],\n",
    "    suffixes=(\"_activity\", \"_oar\")\n",
    ")\n",
    "\n",
    "# Calculate the VALUE for each year, technology, and timeslice\n",
    "merged_data[\"VALUE\"] = merged_data[\"VALUE_activity\"] * merged_data[\"VALUE_oar\"]\n",
    "result = merged_data[[\"TECHNOLOGY\", \"VALUE\", \"YEAR\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Total evapotranspiration\n",
    "Df_evapotranspiration = result.groupby([\"YEAR\"], as_index=False)[\"VALUE\"].sum()\n",
    "\n",
    "#display(Df_evapotranspiration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Water for public use\n",
    "\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "    \n",
    "# Filter data_IAR for the commodity PWRWAT\n",
    "if data_Water_demand_sp[ data_Water_demand_sp[\"COMMODITY\"].isin(Public_water) ].empty:\n",
    "    filtered_demand = data_Water_demand_annual[data_Water_demand_annual[\"COMMODITY\"].isin(Public_water)]\n",
    "else:\n",
    "    filtered_demand = data_Water_demand_sp[data_Water_demand_sp[\"COMMODITY\"].isin(Public_water)]\n",
    "\n",
    "result = filtered_demand[[\"COMMODITY\", \"VALUE\", \"YEAR\"]]\n",
    "\n",
    "# Total demand for public water use\n",
    "Df_Public_demand = result.groupby([\"YEAR\"], as_index=False)[\"VALUE\"].sum()\n",
    "\n",
    "#display(Df_Public_demand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Final water demand\n",
    "\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "    \n",
    "# Merge the three DataFrames on the YEAR column\n",
    "merged_df = pd.merge(Df_Public_demand, Df_Irrigation_demand, on=\"YEAR\", how=\"outer\", suffixes=(\"_public\", \"_irrigation\"))\n",
    "merged_df = pd.merge(merged_df, Df_PWRWAT_demand, on=\"YEAR\", how=\"outer\")\n",
    "merged_df.rename(columns={\"VALUE\": \"VALUE_PWRWAT\"}, inplace=True)\n",
    "merged_df = pd.merge(merged_df, Df_evapotranspiration, on=\"YEAR\", how=\"outer\")\n",
    "merged_df.rename(columns={\"VALUE\": \"VALUE_EVP\"}, inplace=True)\n",
    "\n",
    "# Calculate the total VALUE for each year\n",
    "merged_df[\"VALUE\"] = merged_df[\"VALUE_public\"] + merged_df[\"VALUE_irrigation\"] + merged_df[\"VALUE_PWRWAT\"] #+ merged_df[\"VALUE_EVP\"]\n",
    "\n",
    "# Select the final columns\n",
    "final_water_demand = merged_df[[\"VALUE\", \"YEAR\"]]\n",
    "\n",
    "#display(final_water_demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Available water\n",
    "\n",
    "The methodology used by WRI considers the total available renewable surface and groundwater supplies estimated through a hydrological model. In a CLEWs model this supply comes from the output activity ratios associated to all the land uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Surface water\n",
    "\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "    \n",
    "# Filter data_IAR for the commodity PWRWAT\n",
    "filtered_OAR = data_OAR[data_OAR[\"COMMODITY\"].isin(Surface_water)]\n",
    "\n",
    "# Filter data_Rate_activity for the parameter RateOfTotalActivity\n",
    "filtered_activity = data_activity[data_activity[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Merge the two datasets on REGION, TECHNOLOGY, and YEAR\n",
    "merged_data = pd.merge(\n",
    "    filtered_activity,\n",
    "    filtered_OAR,\n",
    "    on=[\"REGION\", \"TECHNOLOGY\", \"YEAR\"],\n",
    "    suffixes=(\"_activity\", \"_oar\")\n",
    ")\n",
    "\n",
    "# Calculate the VALUE for each year, technology, and timeslice\n",
    "merged_data[\"VALUE\"] = merged_data[\"VALUE_activity\"] * merged_data[\"VALUE_oar\"]\n",
    "result = merged_data[[\"TECHNOLOGY\", \"VALUE\", \"YEAR\"]]\n",
    "\n",
    "\n",
    "# Total surface water supply\n",
    "Df_surface_water = result.groupby([\"YEAR\"], as_index=False)[\"VALUE\"].sum()\n",
    "\n",
    "#display(Df_surface_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Groundwater\n",
    "\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "    \n",
    "# Filter data_IAR for the commodity PWRWAT\n",
    "filtered_OAR = data_OAR[data_OAR[\"COMMODITY\"].isin(Ground_water)]\n",
    "\n",
    "# Filter data_Rate_activity for the parameter RateOfTotalActivity\n",
    "filtered_activity = data_activity[data_activity[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Merge the two datasets on REGION, TECHNOLOGY, and YEAR\n",
    "merged_data = pd.merge(\n",
    "    filtered_activity,\n",
    "    filtered_OAR,\n",
    "    on=[\"REGION\", \"TECHNOLOGY\", \"YEAR\"],\n",
    "    suffixes=(\"_activity\", \"_oar\")\n",
    ")\n",
    "\n",
    "# Calculate the VALUE for each year, technology, and timeslice\n",
    "merged_data[\"VALUE\"] = merged_data[\"VALUE_activity\"] * merged_data[\"VALUE_oar\"]\n",
    "result = merged_data[[\"TECHNOLOGY\", \"VALUE\", \"YEAR\"]]\n",
    "\n",
    "\n",
    "# Total ground water supply\n",
    "Df_ground_water = result.groupby([\"YEAR\"], as_index=False)[\"VALUE\"].sum()\n",
    "\n",
    "#display(Df_ground_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final water supply\n",
    "\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "\n",
    "# Merge the three DataFrames on the YEAR column\n",
    "merged_df = pd.merge(Df_surface_water, Df_ground_water, on=\"YEAR\", how=\"outer\", suffixes=(\"_surface\", \"_groundwater\"))\n",
    "\n",
    "# Calculate the total VALUE for each year\n",
    "merged_df[\"VALUE\"] = merged_df[\"VALUE_surface\"] + merged_df[\"VALUE_groundwater\"]\n",
    "\n",
    "# Select the final columns\n",
    "final_water_supply = merged_df[[\"VALUE\", \"YEAR\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "    \n",
    "# Merge the two DataFrames on the YEAR column\n",
    "merged_df = pd.merge(final_water_demand, final_water_supply, on=\"YEAR\", how=\"inner\", suffixes=(\"_demand\", \"_supply\"))\n",
    "\n",
    "# Calculate the relative water demand = demand / supply\n",
    "merged_df[\"r\"] = merged_df[\"VALUE_demand\"] / merged_df[\"VALUE_supply\"]\n",
    "\n",
    "# Calculate r as usual\n",
    "merged_df[\"r\"] = merged_df[\"VALUE_demand\"] / merged_df[\"VALUE_supply\"]\n",
    "\n",
    "merged_df = merged_df.sort_values(\"YEAR\").reset_index(drop=True)\n",
    "\n",
    "# Calculate scaling factor to match the initial value\n",
    "scaling_factor = Initial_water_stress / merged_df.at[0, \"r\"]\n",
    "\n",
    "# Scale all r values\n",
    "merged_df[\"r\"] = merged_df[\"r\"]*scaling_factor\n",
    "\n",
    "# Calculate ws_aa using the formula\n",
    "merged_df[\"ws_aa\"] = np.minimum(1, np.maximum(0, merged_df[\"r\"]))\n",
    "\n",
    "# Calculate Average_Annual_score using the formula\n",
    "merged_df[\"Average_Annual_score\"] = np.maximum(\n",
    "    0,\n",
    "    np.minimum(\n",
    "        5,\n",
    "        ((np.log(merged_df[\"ws_aa\"]) - np.log(0.1)) / np.log(2)) + 1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Select the final columns to display\n",
    "final_results = merged_df[[\"YEAR\", \"r\", \"Average_Annual_score\"]]\n",
    "\n",
    "# Results DataFrames\n",
    "average_ws_results = merged_df[[\"YEAR\", \"Average_Annual_score\"]].copy()\n",
    "average_ws_results.rename(columns={\"Average_Annual_score\": \"VALUE\"}, inplace=True)\n",
    "average_ws_results[\"INDICATOR\"] = \"AverageAnnualWaterStressScore\"\n",
    "average_ws_results = average_ws_results[[\"INDICATOR\", \"VALUE\", \"YEAR\"]]\n",
    "\n",
    "# Round the values to 3 decimal places\n",
    "average_ws_results[\"VALUE\"] = average_ws_results[\"VALUE\"].round(3)\n",
    "\n",
    "average_r_results = merged_df[[\"YEAR\", \"r\"]].copy()\n",
    "average_r_results.rename(columns={\"r\": \"VALUE\"}, inplace=True)\n",
    "average_r_results[\"INDICATOR\"] = \"r\"\n",
    "average_r_results = average_r_results[[\"INDICATOR\", \"VALUE\", \"YEAR\"]]\n",
    "\n",
    "# Round the values to 3 decimal places\n",
    "average_r_results[\"VALUE\"] = average_r_results[\"VALUE\"].round(3)\n",
    "\n",
    "average_ws_results.to_csv(Annual_average_ws_score, index=False)\n",
    "average_r_results.to_csv(r_csv, index=False)\n",
    "\n",
    "print(f\"Annual average water stress score has been successfully saved to {Annual_average_ws_score}.\")\n",
    "print(f\"Annual relative water demand has been successfully saved to {r_csv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Dependency ratio on crop imports   \n",
    "\n",
    "This indicator estimates the ratio between the annual imports and total annual demand for each crop. Make sure the unit of measure are consistent.<br><br>\n",
    "\n",
    "\n",
    "$$ Crop\\_IDR = \\frac{Total\\_Annual\\_Imports}{Total\\_Annual\\_Demand}$$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crop IDR indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if Crop_IDR == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "output_activity_ratio_csv = os.path.join(converted_input, 'OutputActivityRatio.csv')\n",
    "total_technology_activity_csv = os.path.join(converted_output, 'converted_data.csv')\n",
    "Crop_annual_demand_csv = os.path.join(converted_input, \"AccumulatedAnnualDemand.csv\")\n",
    "output_csv = os.path.join(Final_results, 'Crop_IDR.csv')\n",
    "\n",
    "# Read the input CSV files and standardize column names to uppercase\n",
    "try:\n",
    "    output_activity_ratio_data = pd.read_csv(output_activity_ratio_csv)\n",
    "    total_technology_activity_data = pd.read_csv(total_technology_activity_csv)\n",
    "    crop_annual_demand_data = pd.read_csv(Crop_annual_demand_csv)\n",
    "\n",
    "\n",
    "    # Standardize column names to uppercase\n",
    "    output_activity_ratio_data.columns = output_activity_ratio_data.columns.str.upper()\n",
    "    total_technology_activity_data.columns = total_technology_activity_data.columns.str.upper()\n",
    "    crop_annual_demand_data.columns = crop_annual_demand_data.columns.str.upper()\n",
    "\n",
    "    # Filter for the correct parameter\n",
    "    total_technology_activity_data = total_technology_activity_data[\n",
    "        total_technology_activity_data[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"\n",
    "    ]\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    raise\n",
    "\n",
    "results = {\"CROP\": [], \"VALUE\": [], \"UNIT\": [], \"YEAR\": []}\n",
    "\n",
    "crop_regex = \"|\".join(Crops)  \n",
    "technology_regex = f\"IMP({crop_regex})\"                      \n",
    "\n",
    "for crop in Crops:\n",
    "    crop_technology_regex = f\"IMP{crop}\"\n",
    "    commodity_name = f\"CRP{crop}\"\n",
    "\n",
    "    crop_output_data = output_activity_ratio_data[\n",
    "        (output_activity_ratio_data[\"TECHNOLOGY\"].str.contains(technology_regex, na=False)) &\n",
    "        (output_activity_ratio_data[\"COMMODITY\"] == commodity_name)\n",
    "    ]\n",
    "\n",
    "    crop_activity_data = total_technology_activity_data[\n",
    "        total_technology_activity_data[\"TECHNOLOGY\"].str.contains(technology_regex, na=False)\n",
    "    ]\n",
    "\n",
    "    # Filter Crop Annual Demand data for the current commodity\n",
    "    crop_demand_data = crop_annual_demand_data[\n",
    "        crop_annual_demand_data[\"COMMODITY\"] == commodity_name\n",
    "    ]\n",
    "\n",
    "    for year in crop_activity_data[\"YEAR\"].unique():\n",
    "        year_output_data = crop_output_data[crop_output_data[\"YEAR\"] == year]\n",
    "        year_activity_data = crop_activity_data[crop_activity_data[\"YEAR\"] == year]\n",
    "\n",
    "        # Numerator: sum(OutputActivityRatio * TotalTechnologyAnnualActivity)\n",
    "        numerator = 0\n",
    "        for _, row in year_output_data.iterrows():\n",
    "            technology = row[\"TECHNOLOGY\"]\n",
    "            output_ratio = row[\"VALUE\"]\n",
    "            activity_value = year_activity_data[year_activity_data[\"TECHNOLOGY\"] == technology][\"VALUE\"].sum()\n",
    "            numerator += output_ratio * activity_value\n",
    "\n",
    "        # Denominator: value from Crop Annual Demand for this commodity and year\n",
    "        denominator_row = crop_demand_data[crop_demand_data[\"YEAR\"] == year]\n",
    "        if not denominator_row.empty:\n",
    "            denominator = denominator_row[\"VALUE\"].sum()\n",
    "        else:\n",
    "            denominator = 0\n",
    "\n",
    "        # Calculate the share (%)\n",
    "        if denominator != 0:\n",
    "            share_value = round((numerator / denominator) * 100, 3)\n",
    "            results[\"CROP\"].append(crop)\n",
    "            results[\"VALUE\"].append(share_value)\n",
    "            results[\"UNIT\"].append(\"%\")\n",
    "            results[\"YEAR\"].append(year)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"IDR indicators have been successfully saved to {output_csv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 Harvested area under high managment \n",
    "\n",
    "This indicator calculates the share of harvested area under high managment level calculated as: <br><br>\n",
    "$$HM\\_Area = \\frac{Total\\_land\\_under\\_High\\_managment}{Total\\_land\\_harvested}$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Harvested area under high managment indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if there are no management levels\n",
    "if Managment_level == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "input_csv = os.path.join(converted_output, 'converted_data.csv')\n",
    "output_csv = os.path.join(Final_results, 'HM_area.csv')\n",
    "\n",
    "# Read the input CSV file\n",
    "try:\n",
    "    data = pd.read_csv(input_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_csv} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Filter the data for the parameter \"TotalTechnologyAnnualActivity\"\n",
    "filtered_data = data[data[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {\"INDICATOR\": [], \"VALUE\": [], \"UNIT\": [], \"YEAR\": []}\n",
    "\n",
    "# Build regex for crops, management, and irrigation types\n",
    "crop_regex = \"|\".join(Crops)  # e.g., MAI|RIC|WHT\n",
    "management_regex = \"H|M|L\"    # High, Medium, Low\n",
    "irrigation_regex = \"|\".join(Irrigated)  # e.g., I\n",
    "rainfed_regex = \"|\".join(Rainfed)      # e.g., R\n",
    "\n",
    "# Regex for high management (H) only\n",
    "HM_technology_regex = f\"LND({crop_regex})H({irrigation_regex}|{rainfed_regex})\"\n",
    "# Regex for all management levels\n",
    "total_harvested_technology_regex = f\"LND({crop_regex})({management_regex})({irrigation_regex}|{rainfed_regex})\"\n",
    "\n",
    "for year in filtered_data[\"YEAR\"].unique():\n",
    "    year_data = filtered_data[filtered_data[\"YEAR\"] == year]\n",
    "\n",
    "    # Numerator: High management only\n",
    "    HM_area_data = year_data[year_data[\"TECHNOLOGY\"].str.contains(HM_technology_regex, flags=re.IGNORECASE, na=False)]\n",
    "    HM_area_sum = HM_area_data[\"VALUE\"].sum()\n",
    "\n",
    "    # Denominator: All management levels\n",
    "    total_harvested_area_data = year_data[year_data[\"TECHNOLOGY\"].str.contains(total_harvested_technology_regex, flags=re.IGNORECASE, na=False)]\n",
    "    total_harvested_area_sum = total_harvested_area_data[\"VALUE\"].sum()\n",
    "\n",
    "    if total_harvested_area_sum != 0:\n",
    "        ratio = round((HM_area_sum / total_harvested_area_sum) * 100, 3)\n",
    "        results[\"INDICATOR\"].append(\"HM\")\n",
    "        results[\"VALUE\"].append(ratio)\n",
    "        results[\"UNIT\"].append(\"%\")\n",
    "        results[\"YEAR\"].append(year)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "print(f\"Harvested area under high management indicators have been successfully saved to {output_csv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Forest cover  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if Forest_Cover == False:\n",
    "    exit()\n",
    "\n",
    "# Load the data\n",
    "forest_cover_path = os.path.join(Final_results, 'Forest_cover.csv')\n",
    "forest_cover_data = pd.read_csv(forest_cover_path)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create histogram\n",
    "#plt.bar(forest_cover_data['YEAR'], forest_cover_data['VALUE'], color='lightgreen', alpha=0.7)\n",
    "\n",
    "# Add a trend line\n",
    "plt.plot(forest_cover_data['YEAR'], forest_cover_data['VALUE'], marker='o', color='green')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Forest Cover', fontsize=16)\n",
    "plt.xticks(ticks=forest_cover_data['YEAR'][::5], labels=forest_cover_data['YEAR'][::5], fontsize=12)\n",
    "plt.ylabel('Forest Cover (%)', fontsize=14)\n",
    "plt.ylim(0,100)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(Plots, 'ForestCover.png')\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Harvested area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if Harvested_Area == False:\n",
    "    exit()\n",
    "# Load the data\n",
    "Harvested_path = os.path.join(Final_results, 'Harvested_area.csv')\n",
    "Harvested_data = pd.read_csv(Harvested_path)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create histogram\n",
    "plt.bar(Harvested_data['YEAR'], Harvested_data['VALUE'], color='orange', alpha=0.7)\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Harvested Area', fontsize=16)\n",
    "plt.xticks(ticks=Harvested_data['YEAR'][::5], labels=Harvested_data['YEAR'][::5], fontsize=12)\n",
    "plt.ylabel('Harvested Area (%)', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(Plots, 'HarvestedArea.png')\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Area under irrigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if Irrigated_Area == False:\n",
    "    exit()\n",
    "\n",
    "# Load the data\n",
    "path = os.path.join(Final_results, 'Irrigated_area.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create histogram\n",
    "plt.bar(data['YEAR'], data['VALUE'], alpha=0.7)\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Area under irrigation', fontsize=16)\n",
    "plt.xticks(ticks=data['YEAR'][::5], labels=data['YEAR'][::5], fontsize=12)\n",
    "plt.ylabel('Area under irrigation (%)', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(Plots, 'AreaUnderIrrigation.png')\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Crop yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if Yield == False:\n",
    "    exit()\n",
    "\n",
    "# Load the data\n",
    "path = os.path.join(Final_results, 'Crop_Yield.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Convert the YEAR column to integers\n",
    "data['YEAR'] = data['YEAR'].astype(int)\n",
    "\n",
    "# Sort the data by YEAR for each crop\n",
    "data = data.sort_values(by=['CROP', 'YEAR'])\n",
    "\n",
    "# Plot each crop's data\n",
    "plt.figure(figsize=(10, 6))\n",
    "for crop in data['CROP'].unique():\n",
    "    crop_data = data[data['CROP'] == crop]\n",
    "    plt.plot(crop_data['YEAR'], crop_data['VALUE'], marker='o', linestyle='-', label=crop)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Crop Yields Over Time', fontsize=16)\n",
    "plt.ylabel(f'Yield ({Yield_Unit})', fontsize=14)\n",
    "plt.legend(title='Crop', fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(Plots, 'Crop_Yield.png')\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Biodiversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if BHI == False:\n",
    "    exit()\n",
    "    \n",
    "# Load the data\n",
    "path = os.path.join(Final_results, 'BHI.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot\n",
    "plt.plot(data['YEAR'], data['VALUE'], marker='o', color='darkred')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Biodiversity Habitat Index', fontsize=16)\n",
    "plt.xticks(ticks=data['YEAR'][::5], labels=data['YEAR'][::5], fontsize=12)\n",
    "plt.ylabel('Share of remaining original species (%)', fontsize=14)\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(Plots, 'BHI.png')\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Net emissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if NE == False:\n",
    "    exit()\n",
    "\n",
    "# Load the data\n",
    "path = os.path.join(Final_results, 'Net_emissions.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create histogram\n",
    "#plt.bar(data['YEAR'], data['VALUE'], color='gray', alpha=0.7)\n",
    "\n",
    "# Add a trend line\n",
    "plt.plot(data['YEAR'], data['VALUE'], marker='o', color='darkgray')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(f'Net Emissions ({Emission_Type[0]})', fontsize=16)\n",
    "plt.xticks(ticks=data['YEAR'][::5], labels=data['YEAR'][::5], fontsize=12)\n",
    "plt.ylabel(f'Net Emissions ({Unit_of_measure}) ', fontsize=14)\n",
    "plt.ylim(0)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(Plots, 'NetEmissions.png')\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Relative water demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "\n",
    "# Load the data\n",
    "path = os.path.join(Final_results, 'Relative_annual_water_demand.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create histogram\n",
    "plt.bar(data['YEAR'], data['VALUE'], alpha=0.7)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Relative water demand', fontsize=16)\n",
    "plt.xticks(ticks=data['YEAR'][::5], labels=data['YEAR'][::5], fontsize=12)\n",
    "plt.ylabel('Relative water demand (-)', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(Plots, 'RelativeWaterDemand.png')\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8 Average annual water stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "\n",
    "# Load the data\n",
    "path = os.path.join(Final_results, 'Annual_average_ws_score.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Define colors based on the score range\n",
    "colors = []\n",
    "for value in data['VALUE']:\n",
    "    if 0 <= value < 1:\n",
    "        colors.append('yellow')  \n",
    "    elif 1 <= value < 2:\n",
    "        colors.append(\"#ffca80\")  \n",
    "    elif 2 <= value < 3:\n",
    "        colors.append('orange')\n",
    "    elif 3 <= value < 4:\n",
    "        colors.append('red')\n",
    "    elif 4 <= value <= 5:\n",
    "        colors.append('darkred')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create histogram with conditional colors\n",
    "plt.bar(data['YEAR'], data['VALUE'], color=colors, alpha=0.7)\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Average Annual Water Stress', fontsize=16)\n",
    "plt.xticks(ticks=data['YEAR'][::5], labels=data['YEAR'][::5], fontsize=12)\n",
    "plt.ylabel('Score', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add a legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor= 'yellow' , label='Low (<10%)'),\n",
    "    Patch(facecolor= \"#ffca80\", label='Low-Medium (10-20%)'),\n",
    "    Patch(facecolor='orange', label='Medium - High (20-40%)'),\n",
    "    Patch(facecolor='red', label='High (40-80%)'),\n",
    "    Patch(facecolor='darkred', label='Extremely High (>80%)')\n",
    "]\n",
    "plt.legend(handles=legend_elements, title='Indicator categories', fontsize=12, title_fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(Plots, 'AverageAnnualWaterStress.png')\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9 Crop dependency ratio on imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if Crop_IDR == False:\n",
    "    exit()\n",
    "\n",
    "# Load the data\n",
    "path = os.path.join(Final_results, 'Crop_IDR.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Convert the YEAR column to integers\n",
    "data['YEAR'] = data['YEAR'].astype(int)\n",
    "\n",
    "# Sort the data by YEAR for each crop\n",
    "data = data.sort_values(by=['CROP', 'YEAR'])\n",
    "\n",
    "# Plot each crop's data\n",
    "plt.figure(figsize=(10, 6))\n",
    "for crop in data['CROP'].unique():\n",
    "    crop_data = data[data['CROP'] == crop]\n",
    "    plt.plot(crop_data['YEAR'], crop_data['VALUE'], marker='o', linestyle='-', label=crop)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Dependency ratio on crop imports', fontsize=16)\n",
    "plt.ylabel('Crop IDR (%)', fontsize=14)\n",
    "plt.legend(title='Crop', fontsize=12, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(Plots, 'Crop_IDR.png')\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.10 Harvested area under high managment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if there are no management levels\n",
    "if Managment_level == False:\n",
    "    exit()\n",
    "\n",
    "# Load the data\n",
    "path = os.path.join(Final_results, 'HM_area.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create histogram\n",
    "plt.bar(data['YEAR'], data['VALUE'], alpha=0.7)\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Harvested area under high managment', fontsize=16)\n",
    "plt.xticks(ticks=data['YEAR'][::5], labels=data['YEAR'][::5], fontsize=12)\n",
    "plt.ylabel('Harvested area under high managment (%)', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(Plots, 'High_Managment_Area.png')\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "\n",
    "print(f\"Plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indicators = [Forest_Cover, Harvested_Area, Irrigated_Area, Yield, BHI, NE, ws_aa, Crop_IDR]\n",
    "\n",
    "indicator_names = [\n",
    "    \"Forest_Cover\", \"Harvested_Area\", \"Irrigated_Area\", \"Yield\",\n",
    "    \"BHI\", \"NE\", \"ws_aa\", \"Crop_IDR\"\n",
    "]\n",
    "\n",
    "def analyze_indicators(indicators, names):\n",
    "    true_indicators = []\n",
    "    false_indicators = []\n",
    "    for value, name in zip(indicators, names):\n",
    "        if value:\n",
    "            true_indicators.append(name)\n",
    "        else:\n",
    "            false_indicators.append(name)\n",
    "    \n",
    "    print(f\"The analysis returned the following indicators: {true_indicators}\")\n",
    "    \n",
    "    if false_indicators:\n",
    "        print(f\"If you want to display {false_indicators} indicators, change the settings in the configuration cell.\")\n",
    "\n",
    "analyze_indicators(Indicators, indicator_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otoole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
