{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Indicators4CLEWs_Clusters**  \n",
    "**Original code:** Camilla Lo Giudice  \n",
    "**Supervision:** Francesco Gardumi and Daniel Adshead  \n",
    "**Funding:** IAM COMPACT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the notebook\n",
    "\n",
    "The Notebook can be divided into six sections:  \n",
    "- 1. Initialization\n",
    "- 2. Creation of the directories\n",
    "- 3. Conversion of model input *Data.txt* files into .csv files using otoole\n",
    "- 4. Conversion of model *results.txt* files into 5 result files:\n",
    "    - converted_data.csv\n",
    "    - converted_data_TS.csv : contains all the results with different timeslices\n",
    "    - converted_data_MoO.csv: contains all the results with different modes of operations\n",
    "    - converted_data_Emissions.csv : contains all the results with emission types\n",
    "    - converted_data_MoO_Emissions.csv : contains all the results with emission types and modes of operation\n",
    "- 5. Indicators\n",
    "- 6. Visualization\n",
    "\n",
    "Each part will be further explained and the user will be guided through each step of the notebook. Users are required to customize the naming convention used in their specific model in the section *Configuration*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration - to be filled by the user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part the user has to select the indicators of interest for the analysis. The input and output data used by the user might affect the outcome. For instance, if a result or imput data is missing it won't be possible to display the indicator. \n",
    "\n",
    "1. **How to select the indicator**  \n",
    "For each indicator type the boolean *True* if the indicator is of interest, *False* otherwise\n",
    "\n",
    "2. **Input the name of the variables**  \n",
    "Each model can have similar but different naming conventions for the same technologies or commodities. Input the specific naming convention used in your model. For example *LNDFOR* if that is the name used for the land covered by forest. This will have to be done in the sub-section *Naming convention*. \n",
    "\n",
    "*Assumptions*\n",
    "\n",
    "1) The workflow will assumes a standard format for the crops naming convention: **LND- Crop type - managment level - Irrigated/rainfed.**  \n",
    "For example, if the model has an irrigated maize crop with a high managment level, the name will be: LND-MAI-H-I --> **LNDMAIHI**  \n",
    "\n",
    "2) The same applies for other land types: all of them start with **LND- type.** For example forest will be LND - FOR --> **LNDFOR**\n",
    "\n",
    "3) If there are crop imports, it is assumed that the naming convention will be **IMP** + the same crop names used for the other technolgies. For example for maize, it will be **IMPMAI**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicators\n",
    "\n",
    "Select *True* or *False* for each indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Harvested_Area = True\n",
    "BHI = True                                  #Biodiversity Habitat Index                                 \n",
    "ws_aa = True                                #Average annual water stress\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naming convention\n",
    "\n",
    "Modify the following cell with the varibale names used in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add list of Cluster numbers\n",
    "\"\"\"\n",
    "Here the user can add cluster numbers if the CLEWs model is not on a National scale. \n",
    "The assumed naming convention adds the cluster number after each technology - e.g LNDMAIHRC01 refers to the cluster C01 \n",
    "\n",
    "Example list: Clusters = [\"C01\", \"C02\", \"C03\", \"C04\"]\n",
    "\"\"\"\n",
    "Clusters = [\"C01\", \"C02\", \"C03\", \"C04\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest cover indicator\n",
    "\n",
    "Forest_Land = [\"LNDFOR\"]        #Technology for forest cover\n",
    "Total_Land = [\"LND\"]         #Technology for the land resource\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harvested area indicator\n",
    "\"\"\"\n",
    "Create a list of crops consistent with the naming convention used in your model. \n",
    "This will ensure more flexibility to the workflow. \n",
    "The following list provides commonly used crop names in CLEWs models.\n",
    "\n",
    "Maize = [\"MAI\"]\n",
    "Rice = [\"RIC\"] \n",
    "Cereals = [\"CER\"]\n",
    "Coffee = [\"COF\"]\n",
    "Oilseeds = [\"OIL\"]\n",
    "Pulses = [\"PUL\"]\n",
    "Sugarcane = [\"SUGC\"]\n",
    "Sorghum = [\"SOR\"]\n",
    "Wheat = [\"WHEAT\"]\n",
    "Barley = [\"BAR\"]\n",
    "Soybeans = [\"SOY\"]\n",
    "Other_Crops = [\"OTC\"]\"\n",
    "\n",
    "Example with this list: Crops = [\"MAI\", \"RIC\", \"CER\", \"COF\", \"OIL\", \"PUL\", \"SUGC\", \"SOR\", \"WHEAT\", \"BAR\", \"SOY\", \"OTC\"]\n",
    "\"\"\"\n",
    "\n",
    "Crops = [\"CER\", \"WHE\", \"SOR\", \"COF\", \"BRL\", \"MAI\", \"OTC\"]\n",
    "\n",
    "Irrigated = [\"I\"]                   #Convention for irrigated crops rrigated crops\n",
    "Rainfed = [\"R\"]                     #Convention for rainfed crops rrigated crops \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Managment_level = True     # Select True if your model uses management levels and then define your naming convention\n",
    "\n",
    "\"\"\"\n",
    "Create a list of managment levels if Managment_level = True. \n",
    "The following list provides commonly used names in CLEWs models.\n",
    "\n",
    "High_Management = [\"H\"]  \n",
    "Intermediate_Management = [\"I\"]\n",
    "Low_Management = [\"L\"]\n",
    "\n",
    "Example list: Management_Levels = [\"H\", \"I\", \"L\"]\n",
    "\"\"\"\n",
    "Management_Levels = [\"H\", \"L\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biodiversity Habitat Index (BHI)\n",
    "# create a dictionary of original forest areas for each cluster consistent with the unit used in your model\n",
    "Original_Forest_areas = {\n",
    "    \"C01\": 165.31,\n",
    "    \"C02\": 11.01,\n",
    "    \"C03\": 275.68,\n",
    "    \"C04\": 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average annual water stress\n",
    "\n",
    "\"\"\"\n",
    "Input the name of the commodities used for the water supply.\n",
    "This entails water for public use, power sector or irrigation.\n",
    "\"\"\"\n",
    "\n",
    "#Initial_water_stress = 0.3  # Add the value of the initial water stress in the modelled country for the reference year.\n",
    "                            # You can refer to the water risk atlas --> Water stress (https://www.wri.org/applications/aqueduct/water-risk-atlas)\n",
    "                             \n",
    "#Input the name of the model commodities  \n",
    "Public_water = [\"PUBWAT\"]                  # Commodity name for public water\n",
    "Industrial_water = [\"INDWAT\"]              # Commodity name for industrial water\n",
    "#PWR_water = [\"PWRWAT\"]                     # Commodity name for cooling thermal power plants\n",
    "Irrigation_water = [\"AGRWAT\"]              # Commodity name for irrigation water\n",
    "Surface_water = [\"WTRRUN\"]                 # Commodity name for surface water\n",
    "Ground_water = [\"WTRGWT\"]                  # Commodity name for groundwater\n",
    "Evapotranspiration = [\"WTREVT\"]            # Commodity name for evapotranspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial water stress\n",
    "\n",
    "\"\"\"\n",
    "Fill this disctionary to calibrate the water stress in your model\n",
    "\"\"\"\n",
    "\n",
    "Initial_water_stress = {\n",
    "    \"C01\": 0.2,\n",
    "    \"C02\": 0.3,\n",
    "    \"C03\": 0.1,\n",
    "    \"C04\": 0.4\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python modules or libraries\n",
    "\n",
    "# Numerical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import errno\n",
    "\n",
    "# System & Other\n",
    "import os\n",
    "import re\n",
    "from otoole import convert\n",
    "import csv\n",
    "\n",
    "#Plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creation of the directories  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input data into csv files\n",
    "ROOT_DIR = os.path.abspath(os.curdir)\n",
    "\n",
    "#data and results input by the user\n",
    "conversion_folder = \"convert_from\"\n",
    "input = os.path.join(ROOT_DIR, conversion_folder + \"\\\\\"+ 'data.txt')\n",
    "output = os.path.join(ROOT_DIR, conversion_folder + \"\\\\\"+ 'results.txt')\n",
    "# Path to the configuration file\n",
    "config_file = os.path.join(ROOT_DIR, \"config_com.yaml\")  # Update this path as needed\n",
    "\n",
    "#folder where to save the converted csv files\n",
    "Final_Data= os.path.join(ROOT_DIR, 'Data')\n",
    "if not os.path.exists(Final_Data):\n",
    "    try:\n",
    "        os.makedirs(Final_Data)\n",
    "    except OSError as exc: \n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "Final_results= os.path.join(ROOT_DIR, 'Results')\n",
    "if not os.path.exists(Final_results):\n",
    "    try:\n",
    "        os.makedirs(Final_results)\n",
    "    except OSError as exc: \n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "converted_input = os.path.join(ROOT_DIR, Final_Data + \"\\\\\"+ 'Model input')\n",
    "if not os.path.exists(converted_input):\n",
    "    try:\n",
    "        os.makedirs(converted_input)\n",
    "    except OSError as exc: \n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "converted_output = os.path.join(ROOT_DIR, Final_Data + \"\\\\\"+ 'Model output')\n",
    "if not os.path.exists(converted_output):\n",
    "    try:\n",
    "        os.makedirs(converted_output)\n",
    "    except OSError as exc: \n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "Plots = os.path.join(ROOT_DIR, 'Plots')\n",
    "if not os.path.exists(Plots):\n",
    "    try:\n",
    "        os.makedirs(Plots)\n",
    "    except OSError as exc: \n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conversion of model input Data.txt files into csv\n",
    "This step uses the otoole environment for converting input data into csv files.Then the following three cells convert the results.txt file into three csv files: one with technologies with modes of operation, one with values per each time slice and one with only annual values (not considering neither modes of operation nor time-slices). The converted outputs will be stored into Data/Model input and in Data/Model output folders. The first one is used for the data converted from the data.txt file, while the second one contains the data converted from the results.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix txt file\n",
    "\n",
    "def fix_txt_file(input):\n",
    "    \"\"\"\n",
    "    Fixes the format of the data.txt file into a new data_fixed.txt. \n",
    "    The fixed parameters are `UDCTag`, `OperationalLifeStorage`, `StorageLevelStart`, and `UDCConstant`.\n",
    "    \n",
    "    \"\"\"\n",
    "    output_file = input.replace('.txt', '_fixed.txt')\n",
    "\n",
    "    params_single_line_fix = [\n",
    "        \"UDCTag\",\n",
    "        \"OperationalLifeStorage\",\n",
    "        \"StorageLevelStart\"\n",
    "    ]\n",
    "\n",
    "    params_udc_constant = [\"UDCConstant\"]\n",
    "\n",
    "    with open(input, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    fixed_lines = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        fixed = False\n",
    "\n",
    "        for param in params_single_line_fix:\n",
    "            if line.startswith(f\"param {param} default\"):\n",
    "                if i + 3 < len(lines):\n",
    "                    line2 = lines[i + 1].strip()\n",
    "                    line4 = lines[i + 3].strip()\n",
    "                    if line2 == \":=\" and line4 == \";\":\n",
    "                        cleaned_line = re.sub(r'\\s*:\\s*$', '', line)\n",
    "                        cleaned_line = re.sub(r'\\s*:=\\s*$', '', cleaned_line)\n",
    "                        fixed_lines.append(f\"{cleaned_line} :=\\n\")\n",
    "                        fixed_lines.append(\";\\n\")\n",
    "                        i += 4\n",
    "                        fixed = True\n",
    "                        break\n",
    "\n",
    "        for param in params_udc_constant:\n",
    "            if line.startswith(f\"param {param} default\"):\n",
    "                if i + 5 < len(lines):\n",
    "                    line5 = lines[i + 5].strip()\n",
    "                    if line5 == \";\":\n",
    "                        cleaned_line = re.sub(r'\\s*:\\s*$', '', line)\n",
    "                        cleaned_line = re.sub(r'\\s*:=\\s*$', '', cleaned_line)\n",
    "                        fixed_lines.append(f\"{cleaned_line} :=\\n\")\n",
    "                        fixed_lines.append(\";\\n\")\n",
    "                        i += 6\n",
    "                        fixed = True\n",
    "                        break\n",
    "\n",
    "        if not fixed:\n",
    "            fixed_lines.append(lines[i])\n",
    "            i += 1\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.writelines(fixed_lines)\n",
    "\n",
    "    print(f\"Fixed input file created: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "fixed_input_file = fix_txt_file(input)\n",
    "input_fixed = os.path.join(ROOT_DIR, conversion_folder + \"\\\\\"+ 'data_fixed.txt')\n",
    "print(f\"Fixed file created at: {fixed_input_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input data to CSV files\n",
    "\n",
    "def convert_input_to_csv(config_path, input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts a data.txt file into CSV files and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    config_path : str\n",
    "        Path to the configuration file.\n",
    "    input_path : str\n",
    "        Path to the input data_fixed.txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        try:\n",
    "            os.makedirs(output_folder)\n",
    "        except OSError as exc:\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "    # Perform the conversion\n",
    "    try:\n",
    "        success = convert(\n",
    "            config=config_path,\n",
    "            from_format=\"datafile\",\n",
    "            to_format=\"csv\",\n",
    "            from_path=input_path,\n",
    "            to_path=output_folder,\n",
    "            write_defaults=False,\n",
    "            keep_whitespace=False,\n",
    "        )\n",
    "        return success\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "    \n",
    "# Convert the input data to CSV files\n",
    "conversion_success = convert_input_to_csv(config_file, input_fixed, converted_input)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_input}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conversion of model results.txt file into csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the results to CSV files\n",
    "\n",
    "def convert_results_to_csv(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts the MUIO results.txt file into CSV files and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_path : str\n",
    "        Path to the input txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "  \n",
    "    try:\n",
    "        # Open the input txt file\n",
    "        with open(input_path, 'r') as txt_file:\n",
    "            lines = txt_file.readlines()\n",
    "\n",
    "        # Prepare the output CSV file\n",
    "        output_csv_path = os.path.join(output_folder, \"converted_data.csv\")\n",
    "        with open(output_csv_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the header row\n",
    "            csv_writer.writerow([\"PARAMETER\", \"REGION\", \"TECHNOLOGY\", \"YEAR\", \"VALUE\",])\n",
    "\n",
    "            # Parse each line in the txt file\n",
    "            for line in lines:\n",
    "                # Split the line into columns based on fixed-width formatting\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 3:\n",
    "                    continue  # Skip invalid lines\n",
    "\n",
    "                # Extract the parameter, and values\n",
    "                parameter_info = parts[1]\n",
    "                value = parts[2]\n",
    "\n",
    "                # Parse the parameter info (e.g., NewCapacity(RE1,PWRHYDLRG,2020))\n",
    "                if \"(\" in parameter_info and \")\" in parameter_info:\n",
    "                    parameter, details = parameter_info.split(\"(\")\n",
    "                    details = details.strip(\")\").split(\",\")\n",
    "                    if len(details) == 3:\n",
    "                        region, technology, year = details\n",
    "                        # Write the parsed data to the CSV file\n",
    "                        csv_writer.writerow([parameter, region, technology, year, value,])\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function to convert the custom txt file to CSV\n",
    "conversion_success = convert_results_to_csv(output, converted_output)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_output}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the results to CSV files with TimeSlices\n",
    "\n",
    "def convert_resultsTS_to_csv(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts the MUIO results.txt file into CSV files with time-slices and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_path : str\n",
    "        Path to the input txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "  \n",
    "    try:\n",
    "        # Open the input txt file\n",
    "        with open(input_path, 'r') as txt_file:\n",
    "            lines = txt_file.readlines()\n",
    "\n",
    "        # Prepare the output CSV file\n",
    "        output_csv_TS_path = os.path.join(output_folder, \"converted_data_TS.csv\")\n",
    "        with open(output_csv_TS_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the header row\n",
    "            csv_writer.writerow([\"PARAMETER\", \"REGION\", \"TECHNOLOGY\",\"TIMESLICE\",\"YEAR\", \"VALUE\",])\n",
    "\n",
    "            # Parse each line in the txt file\n",
    "            for line in lines:\n",
    "                # Split the line into columns based on fixed-width formatting\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 4:\n",
    "                    continue  # Skip invalid lines\n",
    "\n",
    "                # Extract the parameter, and values\n",
    "                parameter_info = parts[1]\n",
    "                value = parts[2]\n",
    "\n",
    "                # Parse the parameter info \n",
    "                if \"(\" in parameter_info and \")\" in parameter_info:\n",
    "                    parameter, details = parameter_info.split(\"(\")\n",
    "                    details = details.strip(\")\").split(\",\")\n",
    "                    if len(details) == 4:\n",
    "                        region, technology, time_slice, year = details\n",
    "                        \n",
    "                        # Skip if the time-slice is a number\n",
    "                        if time_slice.isdigit():\n",
    "                            continue\n",
    "\n",
    "                        # Skip if the parameter is \"AnnualTechnologyEmission\" or \"InputToTotalCapacity\"\n",
    "                        if parameter in [\"AnnualTechnologyEmission\", \"InputToTotalCapacity\", \"Demand\"]:\n",
    "                            continue\n",
    "\n",
    "                        # Write the parsed data to the CSV file\n",
    "                        csv_writer.writerow([parameter, region, technology, time_slice, year, value,])\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function to convert the custom txt file to CSV\n",
    "conversion_success = convert_resultsTS_to_csv(output, converted_output)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_output}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the results to CSV files with Modes of operation\n",
    "\n",
    "def convert_resultsMoO_to_csv(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts the MUIO results.txt with modes of operation (MoO) into CSV files with time-slices and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_path : str\n",
    "        Path to the input txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "  \n",
    "    try:\n",
    "        # Open the input txt file\n",
    "        with open(input_path, 'r') as txt_file:\n",
    "            lines = txt_file.readlines()\n",
    "\n",
    "        # Prepare the output CSV file\n",
    "        output_csv_MoO_path = os.path.join(output_folder, \"converted_data_MoO.csv\")\n",
    "        with open(output_csv_MoO_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the header row\n",
    "            csv_writer.writerow([\"PARAMETER\", \"REGION\", \"TECHNOLOGY\",\"MODE_OF_OPERATION\",\"YEAR\", \"VALUE\",])\n",
    "\n",
    "            # Parse each line in the txt file\n",
    "            for line in lines:\n",
    "                # Split the line into columns based on fixed-width formatting\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 4:\n",
    "                    continue  # Skip invalid lines\n",
    "\n",
    "                # Extract the parameter, and values\n",
    "                parameter_info = parts[1]\n",
    "                value = parts[2]\n",
    "\n",
    "                # Parse the parameter info \n",
    "                if \"(\" in parameter_info and \")\" in parameter_info:\n",
    "                    parameter, details = parameter_info.split(\"(\")\n",
    "                    details = details.strip(\")\").split(\",\")\n",
    "                    if len(details) == 4:\n",
    "                        region, technology, mode_of_operation, year = details\n",
    "                        if mode_of_operation.isdigit(): # Modes of operaion can be only > 1\n",
    "                            # Write the parsed data to the CSV file\n",
    "                            csv_writer.writerow([parameter, region, technology, mode_of_operation, year, value,])\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function to convert the custom txt file to CSV\n",
    "conversion_success = convert_resultsMoO_to_csv(output, converted_output)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_output}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the emission results to CSV files \n",
    "\n",
    "def convert_resultsEMI_to_csv(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts the MUIO results.txt file into CSV files with emissions and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_path : str\n",
    "        Path to the input txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "  \n",
    "    try:\n",
    "        # Open the input txt file\n",
    "        with open(input_path, 'r') as txt_file:\n",
    "            lines = txt_file.readlines()\n",
    "\n",
    "        # Prepare the output CSV file\n",
    "        output_csv_EMI_path = os.path.join(output_folder, \"converted_data_Emissions.csv\")\n",
    "        with open(output_csv_EMI_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the header row\n",
    "            csv_writer.writerow([\"PARAMETER\", \"REGION\", \"TECHNOLOGY\",\"EMISSION\",\"YEAR\", \"VALUE\",])\n",
    "\n",
    "            # Parse each line in the txt file\n",
    "            for line in lines:\n",
    "                # Split the line into columns based on fixed-width formatting\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 4:\n",
    "                    continue  # Skip invalid lines\n",
    "\n",
    "                # Extract the parameter, and values\n",
    "                parameter_info = parts[1]\n",
    "                value = parts[2]\n",
    "\n",
    "                # Parse the parameter info \n",
    "                if \"(\" in parameter_info and \")\" in parameter_info:\n",
    "                    parameter, details = parameter_info.split(\"(\")\n",
    "                    details = details.strip(\")\").split(\",\")\n",
    "                    if len(details) == 4:\n",
    "                        region, technology, emission, year = details\n",
    "                        \n",
    "                        # Skip if the time-slice is a number\n",
    "                        if emission.isdigit():\n",
    "                            continue\n",
    "\n",
    "                        # Skip if the parameter is \"AnnualTechnologyEmission\" or \"InputToTotalCapacity\"\n",
    "                        if parameter in [ \"RateOfTotalActivity\",\"InputToTotalCapacity\", \"Demand\"]:\n",
    "                            continue\n",
    "\n",
    "                        # Write the parsed data to the CSV file\n",
    "                        csv_writer.writerow([parameter, region, technology, emission, year, value,])\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function to convert the custom txt file to CSV\n",
    "conversion_success = convert_resultsEMI_to_csv(output, converted_output)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_output}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the emission results to CSV files with Modes of Operation (MoO)\n",
    "\n",
    "def convert_resultsEMIMoO_to_csv(input_path, output_folder):\n",
    "    \"\"\"\n",
    "    Converts the MUIO results.txt file into CSV files with emissions with MoO and stores them in the specified folder.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_path : str\n",
    "        Path to the input txt file.\n",
    "    output_folder : str\n",
    "        Path to the folder where the converted CSV files will be stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the input txt file\n",
    "        with open(input_path, 'r') as txt_file:\n",
    "            lines = txt_file.readlines()\n",
    "\n",
    "        # Prepare the output CSV file\n",
    "        output_csv_EMIMoO_path = os.path.join(output_folder, \"converted_data_MoO_Emissions.csv\")\n",
    "        with open(output_csv_EMIMoO_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the header row\n",
    "            csv_writer.writerow([\"PARAMETER\", \"REGION\", \"TECHNOLOGY\", \"EMISSION\", \"MODE_OF_OPERATION\", \"YEAR\", \"VALUE\"])\n",
    "\n",
    "            # Parse each line in the txt file\n",
    "            for line in lines:\n",
    "                # Split the line into columns based on fixed-width formatting\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 3:  # Ensure the line has enough parts\n",
    "                    #print(f\"Skipping line (not enough parts): {line.strip()}\")\n",
    "                    continue\n",
    "\n",
    "                # Extract the parameter and value\n",
    "                parameter_info = parts[1]\n",
    "                value = parts[2]\n",
    "\n",
    "                # Parse the parameter info\n",
    "                if \"(\" in parameter_info and \")\" in parameter_info:\n",
    "                    parameter, details = parameter_info.split(\"(\")\n",
    "                    details = details.strip(\")\").split(\",\")\n",
    "                    if len(details) == 5:  # Ensure the details have the expected structure\n",
    "                        region, technology, emission, mode, year = details\n",
    "\n",
    "                        if \"Emission\" not in parameter:\n",
    "                            continue\n",
    "\n",
    "                        if not mode.strip().isdigit():\n",
    "                            continue\n",
    "\n",
    "                        if parameter in [ \"RateOfActivity\"]:\n",
    "                            continue\n",
    "\n",
    "                        # Write the parsed data to the CSV file\n",
    "                        csv_writer.writerow([parameter, region, technology, emission, mode, year, value])\n",
    "                    \n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function to convert the custom txt file to CSV\n",
    "conversion_success = convert_resultsEMIMoO_to_csv(output, converted_output)\n",
    "\n",
    "if conversion_success:\n",
    "    print(f\"Data conversion succeeded. CSV files are stored in: {converted_output}\")\n",
    "else:\n",
    "    print(\"Conversion failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Indicators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Harvested area with clusters  \n",
    "This indicator shows the share of total harvested land (both rainfed or irrigated), calculated as <br><br>\n",
    "$$Harvested\\_Area = \\frac{Total\\_land\\_harvested}{Total\\_land}$$\n",
    "\n",
    "Note that the type of crops might vary greatly depending on the case study country. If a specific crop is missing from the ones proposed, add it in the configuration cell. Additionally, models can vary in complexity. A part from distinguishing between rainfed and irrigated, it is possible to model also three generic input/management levels defined in the GAEZ v4.0 model documentation:  \n",
    "- *Low level input:*  \n",
    "   Traditional managment assumption  \n",
    "- *Intermediate level inputs:*  \n",
    "   Improved managment assumption\n",
    "- *High level input:*  \n",
    "   Advanced managment assumption\n",
    "\n",
    "For this indicator the configuration cell will be split in three main cells: managment level, crop types and irrigated/rainfed. This is due to the high flexiility that each user has in shaping the land use. The workflow will assume the standard format used for naming crops: **LND- Crop type - managment level - Irrigated/rainfed.**  \n",
    "\n",
    "For example, if the model has an irrigated maize crop with a high managment level, the name will be: LND-MAI-H-I --> **LNDMAIHI**  \n",
    "\n",
    "\n",
    "For the GAEZ v4 model documentation refer to https://openknowledge.fao.org/server/api/core/bitstreams/6b7b9b4a-dbac-4af4-a2cb-26aff33a30e5/content \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Harvested area indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell for the harvested Area indicator\n",
    "if Harvested_Area == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "input_csv = os.path.join(converted_output, 'converted_data.csv')\n",
    "output_csv = os.path.join(Final_results, 'Harvested_area.csv')\n",
    "\n",
    "# Read the input CSV file\n",
    "try:\n",
    "    data = pd.read_csv(input_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_csv} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Filter the data for the parameter \"TotalTechnologyAnnualActivity\"\n",
    "filtered_data = data[data[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {\"INDICATOR\": [],\"CLUSTER\": [], \"VALUE\": [], \"UNIT\": [], \"YEAR\": []}\n",
    "\n",
    "\n",
    "for cluster in Clusters:\n",
    "    # derive numeric cluster code used by crop technologies (e.g. \"01\" from \"C01\")\n",
    "    crop_cluster = cluster[1:] if cluster.startswith(\"C\") else cluster\n",
    "\n",
    "    # Build the regular expression parts\n",
    "    crop_regex = \"|\".join(Crops)\n",
    "    irrigation_regex = \"|\".join(Irrigated + Rainfed)\n",
    "\n",
    "    # Check if management levels are used and build technology regex for the current cluster's crop code\n",
    "    if Managment_level:\n",
    "        management_regex = \"|\".join(Management_Levels)\n",
    "        technology_regex = rf\"LND({crop_regex})({management_regex})({irrigation_regex})({crop_cluster})\"\n",
    "    else:\n",
    "        technology_regex = rf\"LND({crop_regex})({irrigation_regex})({crop_cluster})\"\n",
    "\n",
    "    # calculate the ratio\n",
    "    for year in filtered_data[\"YEAR\"].unique():\n",
    "        # Filter data for the current year\n",
    "        year_data = filtered_data[filtered_data[\"YEAR\"] == year]\n",
    "\n",
    "        # Filter technologies that match the naming convention for THIS cluster (using numeric cluster part for crops)\n",
    "        harvested_area_data = year_data[year_data[\"TECHNOLOGY\"].str.contains(technology_regex, flags=re.IGNORECASE, na=False)]\n",
    "\n",
    "        # Get the total land value for THIS cluster. Total_Land entries are expected to contain cluster like \"C01\".\n",
    "        total_land_candidates = [t for t in Total_Land if cluster in t]\n",
    "        if total_land_candidates:\n",
    "            total_land_data = year_data[year_data[\"TECHNOLOGY\"].isin(total_land_candidates)]\n",
    "        else:\n",
    "            # fallback: try matching by numeric cluster code if Total_Land doesn't contain full cluster string\n",
    "            total_land_data = year_data[year_data[\"TECHNOLOGY\"].str.contains(crop_cluster, na=False)]\n",
    "\n",
    "        total_land_value = total_land_data[\"VALUE\"].sum()\n",
    "        harvested_area_sum = harvested_area_data[\"VALUE\"].sum()\n",
    "\n",
    "        # Calculate the ratio if total land value is not zero\n",
    "        if total_land_value != 0:\n",
    "            ratio = round((harvested_area_sum / total_land_value) * 100, 3)\n",
    "            results[\"INDICATOR\"].append(\"HarvestedArea\")\n",
    "            results[\"CLUSTER\"].append(cluster)\n",
    "            results[\"VALUE\"].append(ratio)\n",
    "            results[\"UNIT\"].append(\"%\")\n",
    "            results[\"YEAR\"].append(year)\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(['CLUSTER', 'YEAR']).reset_index(drop=True)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "print(f\"Harvested area indicators have been successfully saved to {output_csv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Biodiversity with clusters\n",
    "\n",
    "The Biodiversity Habitat Index (BHI) assesses the effects of habitat loss, degradation, and fragmentation on the retention of terrestrial biodiversity in a region. The indicator exploits the species-area relationship: <br><br><br>\n",
    "\n",
    "\n",
    " $$BHI = \\frac{Forest\\_Area\\_Retained}{Original\\_Forest\\_Area}^{0.25} $$\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " In this analysis, 0.25 represents the exponent *z* of the species–area relationship, a widely accepted value for this type of assessment.\n",
    " The results show the % increase (or decrease) in biodiversity.\n",
    " Being CLEWs models not spatially explicit, we refered to the simplified relationship presented by Simon Ferrier et al. (2004). For more information refer to: BioScience, Volume 54, Issue 12, December 2004, Pages 1101–1109, https://doi.org/10.1641/0006-3568(2004)054[1101:MMOTBF]2.0.CO;2 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BHI indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if BHI == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "input_csv = os.path.join(converted_output, 'converted_data.csv')\n",
    "BHI_output_csv = os.path.join(Final_results, 'BHI.csv')\n",
    "\n",
    "# Read the input CSV file\n",
    "try:\n",
    "    data = pd.read_csv(input_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {input_csv} does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Filter the data for the parameter \"TotalTechnologyAnnualActivity\"\n",
    "filtered_data = data[data[\"PARAMETER\"] == \"TotalTechnologyAnnualActivity\"]\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {\"INDICATOR\": [],\"CLUSTER\": [], \"VALUE\": [], \"UNIT\": [], \"YEAR\": []}\n",
    "\n",
    "for cluster in Clusters:\n",
    "    forest_tech = [t + cluster for t in Forest_Land]\n",
    "    # Loop through each year and calculate the BHI\n",
    "    for year in filtered_data[\"YEAR\"].unique():\n",
    "        # Filter data for the current year\n",
    "        year_data = filtered_data[filtered_data[\"YEAR\"] == year]\n",
    "        \n",
    "        # Get the value for forest land\n",
    "        lndfor_value = year_data[year_data[\"TECHNOLOGY\"].isin(forest_tech)][\"VALUE\"].sum()\n",
    "        \n",
    "        # Calculate the BHI\n",
    "        original_forest_value = Original_Forest_areas[cluster]\n",
    "        if original_forest_value is None:\n",
    "            print(f\"Warning: Original forest area for cluster {cluster} is not defined. Skipping BHI calculation for this cluster.\")\n",
    "            continue\n",
    "        if original_forest_value != 0:\n",
    "            ratio = round(((lndfor_value / original_forest_value) ** 0.25)*100, 3)\n",
    "            results[\"INDICATOR\"].append(\"BHI\")\n",
    "            results[\"CLUSTER\"].append(cluster)\n",
    "            results[\"VALUE\"].append(round(ratio, 3))\n",
    "            results[\"UNIT\"].append(\"%\")\n",
    "            results[\"YEAR\"].append(year)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(['CLUSTER', 'YEAR']).reset_index(drop=True)\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(BHI_output_csv, index=False)\n",
    "\n",
    "print(f\"BHI indicator has been successfully saved to {BHI_output_csv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Average annual water stress and relative water demand\n",
    "\n",
    "The water stress can be calculated as the ratio of the total water demand over the total available renewable surface and groundwater supplies (also known as relative water demand). It is suitable for models with low temporal resolution. The steps for calculating the indicator are the following: <br><br>\n",
    "*Step 1: calculate the relative water demand* <br><br><br>\n",
    "\n",
    "$$r = \\frac{Total\\_Annual\\_Gross\\_Demand}{Total\\_Annual\\_Available\\_Water} $$\n",
    " \n",
    "\n",
    "The annual demand includes public and industrial uses and the demand associated to the power and agricultural sectors.\n",
    "\n",
    "*Step 2: calculate the water average annual stress*<br><br><br>\n",
    "\n",
    "$$ws_{aa} = \\min(1, \\max(0, r))$$\n",
    " \n",
    "*Step 3: conversion to risk categories*<br><br><br>\n",
    "\n",
    "$$Average\\_Annual\\_score = \\max\\left(0, \\min\\left(5, \\frac{ln(ws_{aa})-ln(0.1)}{ln(2)} +1\\right)\\right)$$\n",
    "\n",
    "\n",
    "\n",
    "The risk cathegory follows the same values and methodlogy used by WRI and then adapted to a CLEWs model. The code returns two csv files: one for the relative water demand and one with the average water stress per each modelled year.\n",
    "\n",
    "\n",
    "For more information about the methodology adopted by WRI refer to https://files.wri.org/d8/s3fs-public/2023-08/aqueduct-40-technical-note.pdf?VersionId=G_TxTR2LAnlgXGzy7xtdUP_5lmkXJY7d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "\n",
    "# Paths\n",
    "IAR_csv = os.path.join(converted_input, \"InputActivityRatio.csv\")\n",
    "OAR_csv = os.path.join(converted_input, \"OutputActivityRatio.csv\")\n",
    "Water_annual_demand_sp_csv = os.path.join(converted_input, \"SpecifiedAnnualDemand.csv\")\n",
    "Water_annual_demand_annual_csv = os.path.join(converted_input, \"AccumulatedAnnualDemand.csv\")\n",
    "output_Activity_csv = os.path.join(converted_output, \"converted_data.csv\")\n",
    "output_Activity_MoO_csv = os.path.join(converted_output, \"converted_data_MoO.csv\")\n",
    "Year_split= os.path.join(converted_input, \"YearSplit.csv\")\n",
    "r_csv = os.path.join(Final_results, \"Relative_annual_water_demand.csv\")\n",
    "Annual_average_ws_score = os.path.join(Final_results, \"Annual_average_ws_score.csv\")\n",
    "\n",
    "# Read the input CSV files\n",
    "try:\n",
    "    data_IAR = pd.read_csv(IAR_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {IAR_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_IAR.empty:\n",
    "    print(\"The {IAR_csv} file is empty.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    data_OAR = pd.read_csv(OAR_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {OAR_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_OAR.empty:\n",
    "    print(\"The {OAR_csv} file is empty.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    data_Water_demand_sp = pd.read_csv(Water_annual_demand_sp_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {Water_annual_demand_sp_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_Water_demand_sp[ data_Water_demand_sp[\"COMMODITY\"].isin(Public_water) ].empty:\n",
    "    print(f\"The commodity {Public_water} is not present in {Water_annual_demand_sp_csv}.\")\n",
    "\n",
    "try:\n",
    "    data_Water_demand_annual = pd.read_csv(Water_annual_demand_annual_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {Water_annual_demand_annual_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_Water_demand_annual.empty:\n",
    "    print(\"The {Water_annual_demand_annual_csv} file is empty.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    data_activity = pd.read_csv(output_Activity_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {output_Activity_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_activity.empty:\n",
    "    print(\"The {output_Activity_csv} file is empty.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "try:\n",
    "    data_activity_MoO = pd.read_csv(output_Activity_MoO_csv)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {output_Activity_MoO_csv} does not exist.\")\n",
    "    exit()\n",
    "if data_activity_MoO.empty:\n",
    "    print(\"The {output_Activity_MoO_csv} file is empty.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Water demand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Water demand for industrial demand\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "\n",
    "# Load Year_split data\n",
    "data_Year_split = pd.read_csv(Year_split)\n",
    "\n",
    "# Initialize empty list to store results\n",
    "results = []\n",
    "\n",
    "for cluster in Clusters:\n",
    "    # derive numeric cluster code used by crop technologies (e.g. \"01\" from \"C01\")\n",
    "    demand_cluster = cluster[1:] if cluster.startswith(\"C\") else cluster\n",
    "    \n",
    "    # Create industrial water commodity name for this cluster\n",
    "    industrial_demand = [t + demand_cluster for t in Industrial_water]\n",
    "    \n",
    "    # Get annual demand data\n",
    "    filtered_demand = data_Water_demand_annual[data_Water_demand_annual[\"COMMODITY\"].isin(industrial_demand)]\n",
    "    \n",
    "    # Process each year\n",
    "    unique_years = sorted(data_Year_split[\"YEAR\"].unique())\n",
    "    for year in unique_years:\n",
    "        year_demand = filtered_demand[filtered_demand[\"YEAR\"] == year]\n",
    "        if not year_demand.empty:\n",
    "            annual_value = year_demand[\"VALUE\"].values[0]\n",
    "            # Get year split values for this year\n",
    "            year_splits = data_Year_split[data_Year_split[\"YEAR\"] == year]\n",
    "            \n",
    "            # Calculate for each season\n",
    "            for season in [1, 2]:\n",
    "                # Get timeslices for this season (S11, S12, S13 for season 1, etc.)\n",
    "                season_splits = year_splits[year_splits[\"TIMESLICE\"].str.startswith(f'S{season}')]\n",
    "                \n",
    "                # Calculate seasonal demand (sum of timeslice values * annual demand)\n",
    "                seasonal_demand = annual_value * season_splits[\"VALUE\"].sum()\n",
    "                \n",
    "                # Append result\n",
    "                for commodity in industrial_demand:\n",
    "                    results.append({\n",
    "                        \"COMMODITY\": commodity,\n",
    "                        \"CLUSTER\": cluster,\n",
    "                        \"SEASON\": f\"{season}\",\n",
    "                        \"VALUE\": seasonal_demand,\n",
    "                        \"YEAR\": year\n",
    "                    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "result_industrial_demand = pd.DataFrame(results)\n",
    "# Display the results\n",
    "display(result_industrial_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Irrigation demand\n",
    "\n",
    "#Input the name of the model commodities  \n",
    "Public_water = [\"PUBWAT\"]                  # Commodity name for public water\n",
    "Industrial_water = [\"INDWAT\"]              # Commodity name for industrial water\n",
    "#PWR_water = [\"PWRWAT\"]                     # Commodity name for cooling thermal power plants\n",
    "Irrigation_water = [\"AGRWAT\"]              # Commodity name for irrigation water\n",
    "Surface_water = [\"WTRRUN\"]                 # Commodity name for surface water\n",
    "Ground_water = [\"WTRGWT\"]                  # Commodity name for groundwater\n",
    "Evapotranspiration = [\"WTREVT\"]            # Commodity name for evapotranspiration\n",
    "\n",
    "\n",
    "# Initialize empty list to store results\n",
    "irrigation_results = []\n",
    "\n",
    "# Get unique years from the data\n",
    "unique_years = sorted(data_activity_MoO[\"YEAR\"].unique())\n",
    "\n",
    "# Process each technology activity\n",
    "for _, activity_row in data_activity_MoO.iterrows():\n",
    "    technology = activity_row[\"TECHNOLOGY\"]\n",
    "    year = activity_row[\"YEAR\"]\n",
    "    mode = activity_row[\"MODE_OF_OPERATION\"]\n",
    "    activity_value = activity_row[\"VALUE\"]\n",
    "    \n",
    "    # Extract cluster number from technology (last 2 digits)\n",
    "    cluster = technology[-2:] if technology[-2:].isdigit() else None\n",
    "    if cluster is None:\n",
    "        continue\n",
    "        \n",
    "    # Create corresponding irrigation water commodity name\n",
    "    #irrigation_water = f\"AGRWAT{cluster}\"\n",
    "    \n",
    "    irrigation_water = str(Irrigation_water[0]) + cluster\n",
    "    \n",
    "    # Get corresponding IAR value for the same technology and year\n",
    "    iar_value = data_IAR[\n",
    "        (data_IAR[\"TECHNOLOGY\"] == technology) & \n",
    "        (data_IAR[\"YEAR\"] == year) &\n",
    "        (data_IAR[\"MODE_OF_OPERATION\"] == mode) &\n",
    "        (data_IAR[\"COMMODITY\"] == irrigation_water)\n",
    "    ][\"VALUE\"]\n",
    "    \n",
    "    if not iar_value.empty:\n",
    "        # Calculate total water demand\n",
    "        water_demand = activity_value * iar_value.iloc[0]\n",
    "        \n",
    "        # Determine season based on MODE_OF_OPERATION\n",
    "        season = f\"{mode}\"  # assuming mode 1 -> season 1, mode 2 -> season 2\n",
    "        \n",
    "        # Add to results\n",
    "        irrigation_results.append({\n",
    "            \"TECHNOLOGY\": technology,\n",
    "            \"CLUSTER\": f\"C{cluster}\",  # Adding 'C' prefix to match Clusters format\n",
    "            \"SEASON\": season,\n",
    "            \"VALUE\": water_demand,\n",
    "            \"YEAR\": year\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame and remove duplicates\n",
    "irrigation_result = pd.DataFrame(irrigation_results).drop_duplicates()\n",
    "\n",
    "# Reset index to remove the large index numbers\n",
    "irrigation_result = irrigation_result.reset_index(drop=True)\n",
    "\n",
    "# Aggregate by CLUSTER, SEASON, YEAR\n",
    "result_irrigation_demand = (\n",
    "    irrigation_result\n",
    "    .groupby(['CLUSTER', 'SEASON', 'YEAR'], as_index=False)['VALUE']\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "result_irrigation_demand = result_irrigation_demand[['CLUSTER', 'SEASON', 'VALUE', 'YEAR']]\n",
    "\n",
    "# Sort \n",
    "result_irrigation_demand = result_irrigation_demand.sort_values(['CLUSTER', 'YEAR', 'SEASON']).reset_index(drop=True)\n",
    "\n",
    "# Display the summary\n",
    "display(result_irrigation_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Water for public use\n",
    "\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "\n",
    "# Load Year_split data\n",
    "data_Year_split = pd.read_csv(Year_split)\n",
    "\n",
    "# Initialize empty list to store results\n",
    "results = []\n",
    "\n",
    "for cluster in Clusters:\n",
    "    # derive numeric cluster code used by crop technologies (e.g. \"01\" from \"C01\")\n",
    "    demand_cluster = cluster[1:] if cluster.startswith(\"C\") else cluster\n",
    "    \n",
    "    # Create industrial water commodity name for this cluster\n",
    "    public_demand = [t + demand_cluster for t in Public_water]\n",
    "    \n",
    "    # Get annual demand data\n",
    "    filtered_demand = data_Water_demand_annual[data_Water_demand_annual[\"COMMODITY\"].isin(public_demand)]\n",
    "    \n",
    "    # Process each year\n",
    "    unique_years = sorted(data_Year_split[\"YEAR\"].unique())\n",
    "    for year in unique_years:\n",
    "        year_demand = filtered_demand[filtered_demand[\"YEAR\"] == year]\n",
    "        if not year_demand.empty:\n",
    "            annual_value = year_demand[\"VALUE\"].values[0]\n",
    "            # Get year split values for this year\n",
    "            year_splits = data_Year_split[data_Year_split[\"YEAR\"] == year]\n",
    "            \n",
    "            # Calculate for each season\n",
    "            for season in [1, 2]:\n",
    "                # Get timeslices for this season (S11, S12, S13 for season 1, etc.)\n",
    "                season_splits = year_splits[year_splits[\"TIMESLICE\"].str.startswith(f'S{season}')]\n",
    "                \n",
    "                # Calculate seasonal demand (sum of timeslice values * annual demand)\n",
    "                seasonal_demand = annual_value * season_splits[\"VALUE\"].sum()\n",
    "                \n",
    "                # Append result\n",
    "                for commodity in public_demand:\n",
    "                    results.append({\n",
    "                        \"COMMODITY\": commodity,\n",
    "                        \"CLUSTER\": cluster,\n",
    "                        \"SEASON\": f\"{season}\",\n",
    "                        \"VALUE\": seasonal_demand,\n",
    "                        \"YEAR\": year\n",
    "                    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "result_public_demand = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "display(result_public_demand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Final water demand\n",
    "\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "\n",
    "# Ensure all merge columns are of the same type (string for CLUSTER, int for YEAR, int for SEASON)\n",
    "def _normalize_types(df):\n",
    "    df = df.copy()\n",
    "    df['CLUSTER'] = df['CLUSTER'].astype(str)\n",
    "    df['YEAR'] = df['YEAR'].astype(int)\n",
    "    # Convert SEASON to int if possible, else to string\n",
    "    if df['SEASON'].dtype != 'int64' and df['SEASON'].dtype != 'Int64':\n",
    "        df['SEASON'] = pd.to_numeric(df['SEASON'], errors='coerce').astype('Int64')\n",
    "    return df\n",
    "\n",
    "dfs = [result_irrigation_demand, result_industrial_demand, result_public_demand]\n",
    "dfs = [_normalize_types(df) for df in dfs]\n",
    "\n",
    "# Rename VALUE columns to distinguish them\n",
    "dfs[0] = dfs[0].rename(columns={'VALUE': 'VALUE_IRRIGATION'})\n",
    "dfs[1] = dfs[1].rename(columns={'VALUE': 'VALUE_INDUSTRIAL'})\n",
    "dfs[2] = dfs[2].rename(columns={'VALUE': 'VALUE_PUBLIC'})\n",
    "\n",
    "# Merge all three DataFrames on CLUSTER, SEASON, YEAR (outer join)\n",
    "merged = pd.merge(dfs[0], dfs[1], on=['CLUSTER', 'SEASON', 'YEAR'], how='outer')\n",
    "merged = pd.merge(merged, dfs[2], on=['CLUSTER', 'SEASON', 'YEAR'], how='outer')\n",
    "\n",
    "# Fill NaN with 0 for summing\n",
    "for col in ['VALUE_IRRIGATION', 'VALUE_INDUSTRIAL', 'VALUE_PUBLIC']:\n",
    "    if col in merged.columns:\n",
    "        merged[col] = merged[col].fillna(0)\n",
    "\n",
    "# Calculate total VALUE\n",
    "merged['VALUE'] = merged['VALUE_IRRIGATION'] + merged['VALUE_INDUSTRIAL'] + merged['VALUE_PUBLIC']\n",
    "\n",
    "# Select and reorder columns\n",
    "final_water_demand = merged[['CLUSTER', 'SEASON', 'YEAR', 'VALUE']].sort_values(['CLUSTER', 'YEAR', 'SEASON']).reset_index(drop=True)\n",
    "\n",
    "display(final_water_demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Available water\n",
    "\n",
    "The methodology used by WRI considers the total available renewable surface and groundwater supplies estimated through a hydrological model. In a CLEWs model this supply comes from the output activity ratios associated to all the land uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Surface water\n",
    "\n",
    "# Initialize empty list to store results\n",
    "Surface_water_results = []\n",
    "SurfaceWater = os.path.join(Final_results, 'Surface_water.csv')\n",
    "\n",
    "# Get unique years from the data\n",
    "unique_years = sorted(data_activity_MoO[\"YEAR\"].unique())\n",
    "\n",
    "# List of technology prefixes that need season duplication when mode == 1\n",
    "prefixes = [\"LNDOTHC\", \"LNDBLTC\", \"LNDFORC\", \"LNDWATC\", \"LNDGRSC\"]\n",
    "\n",
    "# Process each technology activity\n",
    "for _, activity_row in data_activity_MoO.iterrows():\n",
    "    technology = activity_row[\"TECHNOLOGY\"]\n",
    "    year = activity_row[\"YEAR\"]\n",
    "    mode = activity_row[\"MODE_OF_OPERATION\"]\n",
    "    activity_value = activity_row[\"VALUE\"]\n",
    "    \n",
    "    # Extract cluster number from technology (last 2 digits)\n",
    "    cluster = technology[-2:] if technology[-2:].isdigit() else None\n",
    "    if cluster is None:\n",
    "        continue\n",
    "        \n",
    "    surface_water = str(Surface_water[0]) + cluster\n",
    "\n",
    "    # Get corresponding OAR value for the same technology and year\n",
    "    oar_value = data_OAR[\n",
    "        (data_OAR[\"TECHNOLOGY\"] == technology) & \n",
    "        (data_OAR[\"YEAR\"] == year) &\n",
    "        (data_OAR[\"MODE_OF_OPERATION\"] == mode) &\n",
    "        (data_OAR[\"COMMODITY\"] == surface_water)\n",
    "    ][\"VALUE\"]\n",
    "    \n",
    "    if not oar_value.empty:\n",
    "        # Calculate total surface water supply\n",
    "        sur_wat_supply = activity_value * oar_value.iloc[0]\n",
    "        \n",
    "        # Check if this is a special technology that needs season duplication\n",
    "        is_special_tech = any(technology.startswith(p) for p in prefixes)\n",
    "        \n",
    "        # For special technologies with mode == 1, duplicate the value for both seasons\n",
    "        if is_special_tech and mode == 1:\n",
    "            Surface_water_results.append({\n",
    "                \"TECHNOLOGY\": technology,\n",
    "                \"CLUSTER\": f\"C{cluster}\",\n",
    "                \"SEASON\": 1,\n",
    "                \"VALUE\": sur_wat_supply,\n",
    "                \"YEAR\": year\n",
    "            })\n",
    "            Surface_water_results.append({\n",
    "                \"TECHNOLOGY\": technology,\n",
    "                \"CLUSTER\": f\"C{cluster}\",\n",
    "                \"SEASON\": 2,\n",
    "                \"VALUE\": sur_wat_supply,\n",
    "                \"YEAR\": year\n",
    "            })\n",
    "        else:\n",
    "            # For all other cases (non-special tech or mode != 1), handle normally\n",
    "            try:\n",
    "                season = int(mode)\n",
    "            except Exception:\n",
    "                season = mode\n",
    "                \n",
    "            Surface_water_results.append({\n",
    "                \"TECHNOLOGY\": technology,\n",
    "                \"CLUSTER\": f\"C{cluster}\",\n",
    "                \"SEASON\": season,\n",
    "                \"VALUE\": sur_wat_supply,\n",
    "                \"YEAR\": year\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame and remove duplicates\n",
    "Surface_water_result = pd.DataFrame(Surface_water_results).drop_duplicates()\n",
    "\n",
    "# Reset index to remove the large index numbers\n",
    "Surface_water_result = Surface_water_result.reset_index(drop=True)\n",
    "\n",
    "# Aggregate by CLUSTER, SEASON, YEAR\n",
    "result_Surface_water_demand = (\n",
    "    Surface_water_result\n",
    "    .groupby(['CLUSTER', 'SEASON', 'YEAR'], as_index=False)['VALUE']\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "result_Surface_water_demand = result_Surface_water_demand[['CLUSTER', 'SEASON', 'VALUE', 'YEAR']]\n",
    "\n",
    "# Sort \n",
    "result_Surface_water_demand = result_Surface_water_demand.sort_values(['CLUSTER', 'YEAR', 'SEASON']).reset_index(drop=True)\n",
    "\n",
    "# Display the summary\n",
    "display(result_Surface_water_demand)\n",
    "\n",
    "\n",
    "\n",
    "result_Surface_water_demand.to_csv(SurfaceWater, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Groundwater\n",
    "# Initialize empty list to store results\n",
    "Groundwater_results = []\n",
    "\n",
    "# Get unique years from the data\n",
    "unique_years = sorted(data_activity_MoO[\"YEAR\"].unique())\n",
    "\n",
    "# List of technology prefixes that need season duplication when mode == 1\n",
    "prefixes = [\"LNDOTHC\", \"LNDBLTC\", \"LNDFORC\", \"LNDWATC\", \"LNDGRSC\"]\n",
    "\n",
    "# Process each technology activity\n",
    "for _, activity_row in data_activity_MoO.iterrows():\n",
    "    technology = activity_row[\"TECHNOLOGY\"]\n",
    "    year = activity_row[\"YEAR\"]\n",
    "    mode = activity_row[\"MODE_OF_OPERATION\"]\n",
    "    activity_value = activity_row[\"VALUE\"]\n",
    "    \n",
    "    # Extract cluster number from technology (last 2 digits)\n",
    "    cluster = technology[-2:] if technology[-2:].isdigit() else None\n",
    "    if cluster is None:\n",
    "        continue\n",
    "        \n",
    "    ground_water = str(Ground_water[0]) + cluster\n",
    "\n",
    "    # Get corresponding OAR value for the same technology and year\n",
    "    oar_value = data_OAR[\n",
    "        (data_OAR[\"TECHNOLOGY\"] == technology) & \n",
    "        (data_OAR[\"YEAR\"] == year) &\n",
    "        (data_OAR[\"MODE_OF_OPERATION\"] == mode) &\n",
    "        (data_OAR[\"COMMODITY\"] == ground_water)\n",
    "    ][\"VALUE\"]\n",
    "    \n",
    "    if not oar_value.empty:\n",
    "        # Calculate total groundwater supply\n",
    "        g_wat_supply = activity_value * oar_value.iloc[0]\n",
    "        \n",
    "        # Check if this is a special technology that needs season duplication\n",
    "        is_special_tech = any(technology.startswith(p) for p in prefixes)\n",
    "        \n",
    "        # For special technologies with mode == 1, duplicate the value for both seasons\n",
    "        if is_special_tech and mode == 1:\n",
    "            Groundwater_results.append({\n",
    "                \"TECHNOLOGY\": technology,\n",
    "                \"CLUSTER\": f\"C{cluster}\",\n",
    "                \"SEASON\": 1,\n",
    "                \"VALUE\": g_wat_supply,\n",
    "                \"YEAR\": year\n",
    "            })\n",
    "            Groundwater_results.append({\n",
    "                \"TECHNOLOGY\": technology,\n",
    "                \"CLUSTER\": f\"C{cluster}\",\n",
    "                \"SEASON\": 2,\n",
    "                \"VALUE\": g_wat_supply,\n",
    "                \"YEAR\": year\n",
    "            })\n",
    "        else:\n",
    "            # For all other cases (non-special tech or mode != 1), handle normally\n",
    "            try:\n",
    "                season = int(mode)\n",
    "            except Exception:\n",
    "                season = mode\n",
    "                \n",
    "            Groundwater_results.append({\n",
    "                \"TECHNOLOGY\": technology,\n",
    "                \"CLUSTER\": f\"C{cluster}\",\n",
    "                \"SEASON\": season,\n",
    "                \"VALUE\": g_wat_supply,\n",
    "                \"YEAR\": year\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame and remove duplicates\n",
    "Groundwater_result = pd.DataFrame(Groundwater_results).drop_duplicates()\n",
    "\n",
    "# Reset index to remove the large index numbers\n",
    "Groundwater_result = Groundwater_result.reset_index(drop=True)\n",
    "\n",
    "# Aggregate by CLUSTER, SEASON, YEAR\n",
    "result_groundwater_demand = (\n",
    "    Groundwater_result\n",
    "    .groupby(['CLUSTER', 'SEASON', 'YEAR'], as_index=False)['VALUE']\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "result_groundwater_demand = result_groundwater_demand[['CLUSTER', 'SEASON', 'VALUE', 'YEAR']]\n",
    "\n",
    "# Sort \n",
    "result_groundwater_demand = result_groundwater_demand.sort_values(['CLUSTER', 'YEAR', 'SEASON']).reset_index(drop=True)\n",
    "\n",
    "# Display the summary\n",
    "display(result_groundwater_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final water supply\n",
    "\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "\n",
    "# Ensure all merge columns are of the same type (string for CLUSTER, int for YEAR, int for SEASON)\n",
    "def _normalize_types(df):\n",
    "    df = df.copy()\n",
    "    df['CLUSTER'] = df['CLUSTER'].astype(str)\n",
    "    df['YEAR'] = df['YEAR'].astype(int)\n",
    "    # Convert SEASON to int if possible, else to string\n",
    "    if df['SEASON'].dtype != 'int64' and df['SEASON'].dtype != 'Int64':\n",
    "        df['SEASON'] = pd.to_numeric(df['SEASON'], errors='coerce').astype('Int64')\n",
    "    return df\n",
    "\n",
    "dfs = [result_groundwater_demand, result_Surface_water_demand]\n",
    "dfs = [_normalize_types(df) for df in dfs]\n",
    "\n",
    "# Rename VALUE columns to distinguish them\n",
    "dfs[0] = dfs[0].rename(columns={'VALUE': 'VALUE_GROUNDWATER'})\n",
    "dfs[1] = dfs[1].rename(columns={'VALUE': 'VALUE_SURFACEWATER'})\n",
    "\n",
    "# Merge all  DataFrames on CLUSTER, SEASON, YEAR (outer join)\n",
    "merged = pd.merge(dfs[0], dfs[1], on=['CLUSTER', 'SEASON', 'YEAR'], how='outer')\n",
    "\n",
    "# Fill NaN with 0 for summing\n",
    "for col in ['VALUE_GROUNDWATER', 'VALUE_SURFACEWATER']:\n",
    "    if col in merged.columns:\n",
    "        merged[col] = merged[col].fillna(0)\n",
    "\n",
    "# Calculate total VALUE\n",
    "merged['VALUE'] = merged['VALUE_GROUNDWATER'] + merged['VALUE_SURFACEWATER']\n",
    "\n",
    "# Select and reorder columns\n",
    "final_water_supply = merged[['CLUSTER', 'SEASON', 'YEAR', 'VALUE']].sort_values(['CLUSTER', 'YEAR', 'SEASON']).reset_index(drop=True)\n",
    "\n",
    "display(final_water_supply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Exit if the indicator is not of interest\n",
    "if ws_aa == False:\n",
    "    exit()\n",
    "\n",
    "# Ensure numpy and pandas are available\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get unique seasons and clusters\n",
    "seasons = sorted(final_water_demand['SEASON'].unique())\n",
    "clusters = sorted(final_water_demand['CLUSTER'].unique())\n",
    "\n",
    "for season in seasons:\n",
    "    # Create season-specific output filenames\n",
    "    season_suffix = f\"_S{season}\"\n",
    "    ws_score_file = Annual_average_ws_score.replace('.csv', f'{season_suffix}.csv')\n",
    "    r_file = r_csv.replace('.csv', f'{season_suffix}.csv')\n",
    "    \n",
    "    # Filter data for this season\n",
    "    demand_season = final_water_demand[final_water_demand['SEASON'] == season]\n",
    "    supply_season = final_water_supply[final_water_supply['SEASON'] == season]\n",
    "    \n",
    "    # Initialize lists to store results\n",
    "    all_ws_results = []\n",
    "    all_r_results = []\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        # If the cluster has no initial-stress entry, skip or handle as needed\n",
    "        if cluster not in Initial_water_stress:\n",
    "            print(f\"Warning: initial water stress not found for cluster '{cluster}'. Skipping cluster.\")\n",
    "            continue\n",
    "        init_ws_cluster = Initial_water_stress[cluster]\n",
    "        \n",
    "        # Filter data for this cluster\n",
    "        demand_cluster = demand_season[demand_season['CLUSTER'] == cluster]\n",
    "        supply_cluster = supply_season[supply_season['CLUSTER'] == cluster]\n",
    "        \n",
    "        # Merge the demand and supply data on YEAR \n",
    "        merged_df = pd.merge(\n",
    "            demand_cluster,\n",
    "            supply_cluster,\n",
    "            on=[\"YEAR\", \"CLUSTER\"],\n",
    "            how=\"inner\",\n",
    "            suffixes=(\"_demand\", \"_supply\")\n",
    "        )\n",
    "        \n",
    "        if merged_df.empty:\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate relative water demand (r) and sort by YEAR\n",
    "        merged_df[\"r\"] = merged_df[\"VALUE_demand\"] / merged_df[\"VALUE_supply\"]\n",
    "        merged_df = merged_df.sort_values(\"YEAR\").reset_index(drop=True)\n",
    "        \n",
    "        # Safety: ensure the first r is non-zero to compute scaling factor\n",
    "        first_r = merged_df.at[0, \"r\"]\n",
    "        if first_r == 0 or np.isclose(first_r, 0.0):\n",
    "            print(f\"Warning: first r is zero for cluster '{cluster}' season {season} (year {merged_df.at[0,'YEAR']}). Skipping scaling for this cluster.\")\n",
    "            # Option A: skip cluster (as above)\n",
    "            continue\n",
    "            # Option B (alternative): set scaling_factor = 1.0\n",
    "            # scaling_factor = 1.0\n",
    "        \n",
    "        # Calculate scaling factor using cluster-specific initial water stress\n",
    "        scaling_factor = init_ws_cluster / first_r\n",
    "        \n",
    "        # Scale all r values\n",
    "        merged_df[\"r\"] = merged_df[\"r\"] * scaling_factor\n",
    "        \n",
    "        # Calculate ws_aa using the formula (clipped between 0 and 1)\n",
    "        merged_df[\"ws_aa\"] = np.minimum(1, np.maximum(0, merged_df[\"r\"]))\n",
    "        \n",
    "        # Calculate Average_Annual_score using the formula\n",
    "        # Note: log of zero is invalid; we ensure ws_aa>0 where used\n",
    "        # To avoid log(0), replace zeros with a tiny positive value for the score computation\n",
    "        safe_ws = merged_df[\"ws_aa\"].replace(0, 1e-12)\n",
    "        merged_df[\"Average_Annual_score\"] = np.maximum(\n",
    "            0,\n",
    "            np.minimum(\n",
    "                5,\n",
    "                ((np.log(safe_ws) - np.log(0.1)) / np.log(2)) + 1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Prepare results for this cluster\n",
    "        # Water stress score results\n",
    "        ws_cluster = merged_df[[\"YEAR\", \"Average_Annual_score\"]].copy()\n",
    "        ws_cluster[\"INDICATOR\"] = \"AverageAnnualWaterStressScore\"\n",
    "        ws_cluster[\"CLUSTER\"] = cluster\n",
    "        ws_cluster.rename(columns={\"Average_Annual_score\": \"VALUE\"}, inplace=True)\n",
    "        ws_cluster = ws_cluster[[\"INDICATOR\", \"CLUSTER\", \"VALUE\", \"YEAR\"]]\n",
    "        ws_cluster[\"VALUE\"] = ws_cluster[\"VALUE\"].round(3)\n",
    "        all_ws_results.append(ws_cluster)\n",
    "        \n",
    "        # Relative water demand results\n",
    "        r_cluster = merged_df[[\"YEAR\", \"r\"]].copy()\n",
    "        r_cluster[\"INDICATOR\"] = \"r\"\n",
    "        r_cluster[\"CLUSTER\"] = cluster\n",
    "        r_cluster.rename(columns={\"r\": \"VALUE\"}, inplace=True)\n",
    "        r_cluster = r_cluster[[\"INDICATOR\", \"CLUSTER\", \"VALUE\", \"YEAR\"]]\n",
    "        r_cluster[\"VALUE\"] = r_cluster[\"VALUE\"].round(3)\n",
    "        all_r_results.append(r_cluster)\n",
    "    \n",
    "    # Combine results from all clusters for this season and save\n",
    "    if all_ws_results:\n",
    "        final_ws = pd.concat(all_ws_results, ignore_index=True)\n",
    "        final_ws.to_csv(ws_score_file, index=False)\n",
    "        print(f\"Season {season} water stress scores saved to {ws_score_file}\")\n",
    "    else:\n",
    "        print(f\"No water stress score results for season {season}.\")\n",
    "    \n",
    "    if all_r_results:\n",
    "        final_r = pd.concat(all_r_results, ignore_index=True)\n",
    "        final_r.to_csv(r_file, index=False)\n",
    "        print(f\"Season {season} relative water demand saved to {r_file}\")\n",
    "    else:\n",
    "        print(f\"No relative-demand results for season {season}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = final_water_supply.copy()\n",
    "tmp[\"SEASON_NUM\"] = tmp[\"SEASON\"].astype(str).str.replace(\"S\", \"\", regex=False).astype(int)\n",
    "\n",
    "# show all matching rows\n",
    "mask = (tmp[\"CLUSTER\"] == \"C04\") & (tmp[\"SEASON_NUM\"] == 2)\n",
    "display(tmp[mask])\n",
    "\n",
    "# show per-year sums\n",
    "display(tmp[mask].groupby(\"YEAR\", as_index=False)[\"VALUE\"].sum())\n",
    "\n",
    "# get value for a single year (e.g. 2020)\n",
    "val_2020 = tmp[mask & (tmp[\"YEAR\"] == 2020)][\"VALUE\"].sum()\n",
    "print(\"VALUE for C04, S2, 2020:\", val_2020)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
